{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "clustering_benchmark.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahandv/science_science/blob/master/clustering_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gg40GIClXPO",
        "outputId": "8ba799a7-cf58-4cda-b290-6a3e43884a77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -rf 'science_science'\n",
        "username = \"sahandv\"#@param {type:\"string\"}\n",
        "# password = \"\"#@param {type:\"string\"} \n",
        "!git clone https://github.com/$username/science_science.git\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'science_science'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 1039 (delta 22), reused 16 (delta 3), pack-reused 1002\u001b[K\n",
            "Receiving objects: 100% (1039/1039), 102.10 MiB | 41.19 MiB/s, done.\n",
            "Resolving deltas: 100% (617/617), done.\n",
            "sample_data  science_science\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIuk5KrtjB3Q",
        "outputId": "1b90c15b-7f96-45ca-9c45-7c4e9b44a0b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!pip install -r 'science_science/requirements.txt'\n",
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 2)) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 3)) (1.1.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 4)) (3.2.5)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 5)) (2.2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 6)) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 7)) (0.16.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 8)) (1.4.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 9)) (0.11.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 10)) (1.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 11)) (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 12)) (7.0.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 13)) (0.8.7)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 14)) (3.6.0)\n",
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 16)) (2.5)\n",
            "Collecting netgraph\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/ed/1e163a923cc58feab143656f2eefd69e5a1d2e323423f62c08b5100a4cbe/netgraph-3.1.8.tar.gz (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: yellowbrick in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 18)) (0.9.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 19)) (4.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r science_science/requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->-r science_science/requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r science_science/requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (50.3.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (2.0.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r science_science/requirements.txt (line 6)) (0.17.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r science_science/requirements.txt (line 7)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r science_science/requirements.txt (line 7)) (1.1.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r science_science/requirements.txt (line 11)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r science_science/requirements.txt (line 11)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r science_science/requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->-r science_science/requirements.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->-r science_science/requirements.txt (line 15)) (0.35.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->-r science_science/requirements.txt (line 15)) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->-r science_science/requirements.txt (line 15)) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->-r science_science/requirements.txt (line 15)) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->-r science_science/requirements.txt (line 15)) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->-r science_science/requirements.txt (line 16)) (4.4.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->-r science_science/requirements.txt (line 19)) (1.3.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r science_science/requirements.txt (line 5)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r science_science/requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r science_science/requirements.txt (line 5)) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r science_science/requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->-r science_science/requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis->-r science_science/requirements.txt (line 15)) (1.1.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->-r science_science/requirements.txt (line 15)) (8.5.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->-r science_science/requirements.txt (line 15)) (1.9.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->-r science_science/requirements.txt (line 15)) (20.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->-r science_science/requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->-r science_science/requirements.txt (line 15)) (0.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->-r science_science/requirements.txt (line 5)) (3.3.1)\n",
            "Building wheels for collected packages: pyLDAvis, netgraph\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=5a3dcaf7d23e35fa488c0611174890f910fdffa717482d0b1a64c642263d9794\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for netgraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for netgraph: filename=netgraph-3.1.8-cp36-none-any.whl size=45928 sha256=6a637407fdb041486208b1e4a7b8d62256998b1aeb7274a4aff613375206d55e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/c2/49/30a980fcf7c864676d6184e46ea8860fff2b7fa6f324cad69a\n",
            "Successfully built pyLDAvis netgraph\n",
            "Installing collected packages: funcy, pyLDAvis, netgraph\n",
            "Successfully installed funcy-1.15 netgraph-3.1.8 pyLDAvis-2.1.2\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.6.20)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.3.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh7k1URJ7UVR"
      },
      "source": [
        "# datapath = '/mnt/6016589416586D52/Users/z5204044/GoogleDrive/GoogleDrive/Data/' # Local C1314\n",
        "# datapath = '/mnt/16A4A9BCA4A99EAD/GoogleDrive/Data/' # Local Ryzen\n",
        "datapath = 'drive/My Drive/Data/' # Remote"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QunjBk8t7UVW"
      },
      "source": [
        "# Remote\n",
        "from science_science.sciosci.assets import text_assets as ta\n",
        "from science_science.DEC.DEC_keras import DEC_simple_run\n",
        "\n",
        "# Local\n",
        "# from sciosci.assets import text_assets as ta\n",
        "# from DEC.DEC_keras import DEC_simple_run"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ST9wwa7iqRr"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import gc\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans, DBSCAN\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics.cluster import silhouette_score,homogeneity_score,adjusted_rand_score\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score,adjusted_mutual_info_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import TfidfTransformer , TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Load data and init\n",
        "# =============================================================================\n",
        "data_address =  datapath+\"Corpus/KPRIS/embeddings/deflemm/Doc2Vec patent_wos corpus\"\n",
        "label_address =  datapath+\"Corpus/KPRIS/labels\"\n",
        "\n",
        "vectors = pd.read_csv(data_address)\n",
        "labels = pd.read_csv(label_address,names=['label'])\n",
        "labels_f = pd.factorize(labels.label)\n",
        "X = vectors.values\n",
        "Y = labels_f[0]\n",
        "n_clusters = 5\n",
        "\n",
        "labels_task_1 = labels[(labels['label']=='car') | (labels['label']=='memory')]\n",
        "vectors_task_1 = vectors.iloc[labels_task_1.index]\n",
        "labels_task_1_f = pd.factorize(labels_task_1.label)\n",
        "X_task_1 = vectors_task_1.values\n",
        "Y_task_1 = labels_task_1_f[0]\n",
        "n_clusters_task_1 = 2\n",
        "\n",
        "results = pd.DataFrame([],columns=['Method','parameter','Silhouette','Homogeneity','NMI','AMI','ARI'])\n",
        "# =============================================================================\n",
        "# Evaluation method\n",
        "# =============================================================================\n",
        "def evaluate(X,Y,predicted_labels):\n",
        "    \n",
        "    df = pd.DataFrame(predicted_labels,columns=['label'])\n",
        "    if len(df.groupby('label').groups)<2:\n",
        "        return [0,0,0,0,0]\n",
        "    \n",
        "    return [silhouette_score(X, predicted_labels, metric='euclidean'),\n",
        "                    homogeneity_score(Y, predicted_labels),\n",
        "                    normalized_mutual_info_score(Y, predicted_labels),\n",
        "                    adjusted_mutual_info_score(Y, predicted_labels),\n",
        "                    adjusted_rand_score(Y, predicted_labels)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWpVWF_DisHc"
      },
      "source": [
        "\n",
        "# =============================================================================\n",
        "# K-means\n",
        "# =============================================================================\n",
        "print('\\n- k-means random -----------------------')\n",
        "for fold in tqdm(range(20)):\n",
        "    seed = randint(0,10**5)\n",
        "    model = KMeans(n_clusters=n_clusters,n_init=20, init='random', random_state=seed).fit(X)\n",
        "    predicted_labels = model.labels_\n",
        "    tmp_results = ['k-means random','seed '+str(seed)]+evaluate(X,Y,predicted_labels)\n",
        "    tmp_results = pd.Series(tmp_results, index = results.columns)\n",
        "    results = results.append(tmp_results, ignore_index=True)\n",
        "mean = results.mean(axis=0)\n",
        "maxx = results.max(axis=0)\n",
        "print(mean)\n",
        "print(maxx)\n",
        "# =============================================================================\n",
        "# K-means with init='k-means++'\n",
        "# =============================================================================\n",
        "print('\\n- k-means++ -----------------------')\n",
        "for fold in tqdm(range(20)):\n",
        "    seed = randint(0,10**5)\n",
        "    model = KMeans(n_clusters=n_clusters,n_init=20,init='k-means++', random_state=seed).fit(X)\n",
        "    predicted_labels = model.labels_\n",
        "    tmp_results = ['k-means++','seed '+str(seed)]+evaluate(X,Y,predicted_labels)\n",
        "    tmp_results = pd.Series(tmp_results, index = results.columns)\n",
        "    results = results.append(tmp_results, ignore_index=True)\n",
        "mean = results.mean(axis=0)\n",
        "maxx = results.max(axis=0)\n",
        "print(mean)\n",
        "print(maxx)\n",
        "# =============================================================================\n",
        "# Agglomerative\n",
        "# =============================================================================\n",
        "print('\\n- Agglomerative -----------------------')\n",
        "for fold in tqdm(range(4)):\n",
        "    model = AgglomerativeClustering(n_clusters=n_clusters,linkage='ward').fit(X)\n",
        "    predicted_labels = model.labels_\n",
        "    tmp_results = ['Agglomerative','ward']+evaluate(X,Y,predicted_labels)\n",
        "    tmp_results = pd.Series(tmp_results, index = results.columns)\n",
        "    results = results.append(tmp_results, ignore_index=True)\n",
        "mean = results.mean(axis=0)\n",
        "maxx = results.max(axis=0)\n",
        "print(mean)\n",
        "print(maxx)\n",
        "# =============================================================================\n",
        "# DBSCAN\n",
        "# =============================================================================\n",
        "eps=0.000001\n",
        "print('\\n- DBSCAN -----------------------')\n",
        "for fold in tqdm(range(19)):\n",
        "    eps = eps+0.05\n",
        "    model = DBSCAN(eps=eps, min_samples=10,n_jobs=15).fit(X)\n",
        "    predicted_labels = model.labels_\n",
        "    tmp_results = ['DBSCAN','eps '+str(eps)]+evaluate(X,Y,predicted_labels)\n",
        "    tmp_results = pd.Series(tmp_results, index = results.columns)\n",
        "    results = results.append(tmp_results, ignore_index=True)\n",
        "mean = results.mean(axis=0)\n",
        "maxx = results.max(axis=0)\n",
        "print(mean)\n",
        "print(maxx)\n",
        "# =============================================================================\n",
        "# Deep no min_max_scaling\n",
        "# =============================================================================\n",
        "archs = [[500, 500, 2000, 10],[500, 1000, 2000, 10],[500, 1000, 1000, 10],\n",
        "         [500, 500, 2000, 100],[500, 1000, 2000, 100],[500, 1000, 1000, 100],\n",
        "         [100, 300, 600, 10],[300, 500, 2000, 10],[700, 1000, 2000, 10],\n",
        "         [200, 500, 10],[500, 1000, 10],[1000, 2000, 10],\n",
        "         [200, 500, 100],[500, 1000, 100],[1000, 2000, 100],\n",
        "         [1000, 500, 10],[500, 200, 10],[200, 100, 10],\n",
        "         [1000, 1000, 2000, 10],[1000, 1500, 2000, 10],[1000, 1500, 1000, 10],\n",
        "         [1000, 1000, 2000,500, 10],[1000, 1500, 2000,500, 10],[1000, 1500, 1000, 500, 10],\n",
        "         [500, 500, 2000, 500, 10],[500, 1000, 2000, 500, 10],[500, 1000, 1000, 500, 10]]\n",
        "print('\\n- DEC -----------------------')\n",
        "for fold in tqdm(archs):\n",
        "    seed = randint(0,10**4)\n",
        "    np.random.seed(seed)\n",
        "    predicted_labels = DEC_simple_run(X,minmax_scale_custom_data=False,n_clusters=5,architecture=fold,pretrain_epochs=400)\n",
        "    tmp_results = ['DEC',str(seed)+' '+str(fold)]+evaluate(X,Y,predicted_labels)\n",
        "    tmp_results = pd.Series(tmp_results, index = results.columns)\n",
        "    results = results.append(tmp_results, ignore_index=True)\n",
        "mean = results.mean(axis=0)\n",
        "maxx = results.max(axis=0)\n",
        "print(mean)\n",
        "print(maxx)\n",
        "# =============================================================================\n",
        "# Deep with min_max_scaling\n",
        "# =============================================================================\n",
        "archs = [[500, 500, 2000, 10],[500, 1000, 2000, 10],[500, 1000, 1000, 10],\n",
        "         [500, 500, 2000, 100],[500, 1000, 2000, 100],[500, 1000, 1000, 100],\n",
        "         [100, 300, 600, 10],[300, 500, 2000, 10],[700, 1000, 2000, 10],\n",
        "         [200, 500, 10],[500, 1000, 10],[1000, 2000, 10],\n",
        "         [200, 500, 100],[500, 1000, 100],[1000, 2000, 100],\n",
        "         [1000, 500, 10],[500, 200, 10],[200, 100, 10],\n",
        "         [1000, 1000, 2000, 10],[1000, 1500, 2000, 10],[1000, 1500, 1000, 10],\n",
        "         [1000, 1000, 2000,500, 10],[1000, 1500, 2000,500, 10],[1000, 1500, 1000, 500, 10],\n",
        "         [500, 500, 2000, 500, 10],[500, 1000, 2000, 500, 10],[500, 1000, 1000, 500, 10]]\n",
        "print('\\n- DEC -----------------------')\n",
        "for fold in tqdm(archs):\n",
        "    seed = randint(0,10**4)\n",
        "    np.random.seed(seed)\n",
        "    predicted_labels = DEC_simple_run(X,minmax_scale_custom_data=False,n_clusters=5,architecture=fold,pretrain_epochs=400)\n",
        "    tmp_results = ['DEC',str(seed)+' '+str(fold)]+evaluate(X,Y,predicted_labels)\n",
        "    tmp_results = pd.Series(tmp_results, index = results.columns)\n",
        "    results = results.append(tmp_results, ignore_index=True)\n",
        "mean = results.mean(axis=0)\n",
        "maxx = results.max(axis=0)\n",
        "print(mean)\n",
        "print(maxx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAlZI5NwiuHG"
      },
      "source": [
        "# =============================================================================\n",
        "# Save to disk\n",
        "# =============================================================================\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(data_address+' clustering results _ new',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfxkBGq9HBO3"
      },
      "source": [
        "Mini test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hILmmi_qG9IH"
      },
      "source": [
        "# =============================================================================\n",
        "# Deep no min_max_scaling\n",
        "# =============================================================================\n",
        "archs = [[200,200,10],[200,200,10],[200,200,10],\n",
        "        [200,200,10],[200,200,10],[200,200,10],\n",
        "        [200,200,10],[200,200,10],[200,200,10],\n",
        "        [200,500,10],[200,500,10],[200,500,10],\n",
        "        [200,200,10],[200,200,10],[200,200,10],\n",
        "        [200,200,10],[200,200,10],[200,200,10],\n",
        "        [200,200,10],[200,200,10],[200,200,10],\n",
        "        [200,200,10],[200,200,10],[200,200,10],\n",
        "        [200,200,10],[200,200,10],[200,200,10],\n",
        "        [200,200,10],[200,200,10],[200,200,10],\n",
        "        [200,200,10],[200,200,10],[200,200,10]]\n",
        "\n",
        "print('\\n- DEC -----------------------')\n",
        "for fold in tqdm(archs):\n",
        "    seed = randint(0,10**5)\n",
        "    np.random.seed(seed)\n",
        "    predicted_labels = DEC_simple_run(X,minmax_scale_custom_data=False,n_clusters=5,architecture=fold,pretrain_epochs=400)\n",
        "    tmp_results = ['DEC',str(seed)+' '+str(fold)]+evaluate(X,Y,predicted_labels)\n",
        "    tmp_results = pd.Series(tmp_results, index = results.columns)\n",
        "    results = results.append(tmp_results, ignore_index=True)\n",
        "mean = results.mean(axis=0)\n",
        "maxx = results.max(axis=0)\n",
        "print(mean)\n",
        "print(maxx)\n",
        "# =============================================================================\n",
        "# Save to disk\n",
        "# =============================================================================\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(data_address+' clustering results _ DEC fixed seed',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}