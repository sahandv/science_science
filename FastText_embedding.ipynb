{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sahandv/science_science/blob/master/FastText_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B43KQKxsZqK2"
   },
   "source": [
    "# FASTTEXT EMBEDDING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyakRMAwbUq2"
   },
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8klZfiWyEt98"
   },
   "source": [
    "Local OR Colab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bsEwsoJSEtKx"
   },
   "outputs": [],
   "source": [
    "datapath = '/home/sahand/GoogleDrive/Data/' # Local\n",
    "# datapath = 'drive/My Drive/Data/' # Remote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIPuXPla6BKh"
   },
   "source": [
    "### Clone Project Git Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "j-YQSyFe6Bgv",
    "outputId": "317e9398-51e9-4ca2-ff1d-d5cc25237afd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'science_science'...\n",
      "remote: Enumerating objects: 148, done.\u001b[K\n",
      "remote: Counting objects: 100% (148/148), done.\u001b[K\n",
      "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
      "remote: Total 565 (delta 79), reused 60 (delta 17), pack-reused 417\u001b[K\n",
      "Receiving objects: 100% (565/565), 81.91 MiB | 14.20 MiB/s, done.\n",
      "Resolving deltas: 100% (281/281), done.\n",
      "drive  sample_data  science_science\n"
     ]
    }
   ],
   "source": [
    "!rm -rf 'science_science'\n",
    "username = \"sahandv\"#@param {type:\"string\"}\n",
    "# password = \"\"#@param {type:\"string\"} \n",
    "\n",
    "!git clone https://github.com/$username/science_science.git\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8crXh0Ek1FA"
   },
   "source": [
    "### Mount Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ulliMrpjkKAd",
    "outputId": "f6af6df2-2b05-4b5c-8527-619ffb075ed8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nhV7OflrnOhI",
    "outputId": "f4eef4ec-c649-4790-8387-2c3290a7ebfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawl-300d-2M-subword.bin  crawl-300d-2M-subword.vec\n"
     ]
    }
   ],
   "source": [
    "# Check files!\n",
    "!ls 'drive/My Drive/Data-Permenant/FastText-crawl-300d-2M-subword'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiBuMInGmypx"
   },
   "source": [
    "### Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7OwQMHvQmy3A",
    "outputId": "f44f247d-264f-45b4-a976-5efa9a52c511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.1.3)\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 1)) (1.18.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 2)) (4.38.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 3)) (1.0.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 4)) (3.2.5)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 5)) (2.2.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 6)) (0.22.2.post1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 7)) (0.16.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 8)) (1.4.1)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 9)) (0.10.0)\n",
      "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 10)) (1.5.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 11)) (3.2.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 12)) (7.0.0)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 13)) (0.8.7)\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 14)) (3.8.1)\n",
      "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 15)) (2.1.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 16)) (2.4)\n",
      "Requirement already satisfied: netgraph in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 17)) (3.1.6)\n",
      "Requirement already satisfied: yellowbrick in /usr/local/lib/python3.6/dist-packages (from -r science_science/requirements.txt (line 18)) (0.9.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r science_science/requirements.txt (line 3)) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r science_science/requirements.txt (line 3)) (2.8.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r science_science/requirements.txt (line 4)) (1.12.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (2.0.3)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (7.4.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (2.21.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (0.6.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (46.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r science_science/requirements.txt (line 5)) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r science_science/requirements.txt (line 6)) (0.14.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r science_science/requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r science_science/requirements.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r science_science/requirements.txt (line 11)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r science_science/requirements.txt (line 11)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r science_science/requirements.txt (line 11)) (2.4.6)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim->-r science_science/requirements.txt (line 14)) (1.10.0)\n",
      "Requirement already satisfied: funcy in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->-r science_science/requirements.txt (line 15)) (1.14)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->-r science_science/requirements.txt (line 15)) (2.11.1)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->-r science_science/requirements.txt (line 15)) (0.34.2)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->-r science_science/requirements.txt (line 15)) (2.7.1)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->-r science_science/requirements.txt (line 15)) (3.6.4)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->-r science_science/requirements.txt (line 15)) (0.16.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->-r science_science/requirements.txt (line 16)) (4.4.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->-r science_science/requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r science_science/requirements.txt (line 5)) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r science_science/requirements.txt (line 5)) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r science_science/requirements.txt (line 5)) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r science_science/requirements.txt (line 5)) (3.0.4)\n",
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (1.18.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (1.12.35)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis->-r science_science/requirements.txt (line 15)) (1.1.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->-r science_science/requirements.txt (line 15)) (1.8.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->-r science_science/requirements.txt (line 15)) (8.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->-r science_science/requirements.txt (line 15)) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->-r science_science/requirements.txt (line 15)) (19.3.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->-r science_science/requirements.txt (line 15)) (0.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->-r science_science/requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (1.0.3)\n",
      "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (0.4.1)\n",
      "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (1.7.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (0.9.5)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.35 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (1.15.35)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (0.3.3)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (4.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (3.1.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.35->boto3->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (0.15.2)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (3.10.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (1.51.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim->-r science_science/requirements.txt (line 14)) (0.4.8)\n",
      "Requirement already satisfied: gensim==3.8.1 in /usr/local/lib/python3.6/dist-packages (3.8.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.10.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.1) (1.18.2)\n",
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (1.18.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (1.12.35)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim==3.8.1) (2.21.0)\n",
      "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (0.4.1)\n",
      "Requirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (1.7.2)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (1.0.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.35 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (1.15.35)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim==3.8.1) (0.9.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim==3.8.1) (3.0.4)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (46.1.3)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (0.2.8)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (1.16.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.35->boto3->smart-open>=1.8.1->gensim==3.8.1) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.35->boto3->smart-open>=1.8.1->gensim==3.8.1) (2.8.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth>=1.2.0->google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (0.4.8)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (1.51.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (2018.9)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->smart-open>=1.8.1->gensim==3.8.1) (3.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext\n",
    "!pip install -r 'science_science/requirements.txt'\n",
    "!pip install gensim==3.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9l5YuBnkKFB"
   },
   "source": [
    "### Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4sdVZl-kKI3"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import json\n",
    "import re\n",
    "\n",
    "import fasttext\n",
    "import gensim\n",
    "from gensim.models import FastText as fasttext_gensim\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sciosci.assets import keyword_assets as kw\n",
    "from sciosci.assets import generic_assets as sci\n",
    "from sciosci.assets import advanced_assets as aa\n",
    "\n",
    "# from science_science.sciosci.assets import keyword_assets as kw\n",
    "# from science_science.sciosci.assets import generic_assets as sci\n",
    "# from science_science.sciosci.assets import advanced_assets as aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wu17lpjOg7F2"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "draRfEpf8A5L",
    "outputId": "064ad629-dfb0-41ec-80f4-2d05b2a4a144"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sahand/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sahand/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sahand/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "stops = ['a','an','we','result','however','yet','since','previously','although','propose','proposed','e_g','method',\n",
    "         'published_elsevier','b','v','problem','paper','approach','within','with','by','via','way','t','case','issue','level','area','system',\n",
    "         'work','discussed','seen','put','usually','take','make','author','versus','enables','result','research','design','based']\n",
    "punkts = [' ','','(',')','[',']','{','}','.',',','!','?','<','>','-','_',':',';','\\\\','/','|','&','%',\"'s\",\"`s\",'#','$','@']\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = list(set(stopwords.words(\"english\")))+stops+punkts\n",
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iLK4cDhVkKbs"
   },
   "source": [
    "# Get embeddings from a pre-trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WhKPivNafWBf"
   },
   "source": [
    "### Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQEzlLSQ6g0E"
   },
   "outputs": [],
   "source": [
    "period = '2014-2016'\n",
    "percentile = 97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6XYOAVzkKsR"
   },
   "source": [
    "#### Option A - Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PkWEF6DBkKzd",
    "outputId": "7a455fdb-1f8b-40f0-fbc9-4135f5932170"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = datapath+'Corpus/copyr_lemmatized_stopword_removed_thesaurus/by period/uni-grams/'\n",
    "file_name = period+' abstract_title'#corpus abstract-title - with n-grams'\n",
    "corpus = pd.read_csv(directory+file_name,names=['abstracts'])\n",
    "corpus_tokens = [item for sublist in corpus['abstracts'].values.tolist() for item in sublist.split()]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "zFwzf5Aa34G8",
    "outputId": "24243a66-5d0e-4d8f-90af-edcf018e8576"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human machine interaction facial expression re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rule base fuzzy cognitive map natural language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fog compute architecture healthcare wireless p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>argumentation knowledge representation conflic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hydrothermal coordination power system scale i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>statistical method manage miss data applicatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intelligent digital signal processing feature ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dewey enactivism greek thought chapter examine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>artificial vision manufacturing system artific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>overview application image processing technolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>artificial neural network anfis model failure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>urban water consumption estimation artificial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>conceptual model intelligent simulation base l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>internet thing cognitive compute internet thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>error bound probabilistically optimal problem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>processing electrical signal heart machine lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>technology versus human effect minimum wage lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>artificial intelligence aircraft conceptual de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>scalebook vemus literacy software tool vemus s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>improve incremental training approach scale da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>review semi supervise method intrusion detecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rough set fuzzy logic approach handwritten dig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>comparison empirical study short time forecast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>intelligent collision avoidance algorithm rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>line soft sense model base maximum power point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dynamic fuzzy cluster method decision support ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>agent base approach smart transport system pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>artificial intelligence workbench retrospectiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>e commerce customer service robot base intenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>verification validation pddl description event...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>improve fault classification series compensate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>rainstorm flash flood risk assessment genetic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>coalition formation decision support system ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>artificial intelligence tool argument evaluati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>novel benchmark database digitize calibrate ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6193</th>\n",
       "      <td>spectrum base modal parameter identification p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>edge singularity present paper touch prelimina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>narrow optimization short horizon argument bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>application pattern recognition detection bury...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>translation imagine perceive execute accord sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>design make translation imagine perceive execu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>potential computational fluid dynamic simulati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6200</th>\n",
       "      <td>knowledge model system ready mixed concrete en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>artificial intelligence approach classify unip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>support vector machine model particle swarm op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6203</th>\n",
       "      <td>artificial intelligence service orient softwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>popponent highly accurate individually sociall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6205</th>\n",
       "      <td>hybrid modify evolutionary particle swarm opti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6206</th>\n",
       "      <td>temporal response chemically diverse sensor ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6207</th>\n",
       "      <td>evaluate morphological computation muscle dc m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>ground humanoid visually guide walk action ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>mapreduce base distribute learn algorithm rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6210</th>\n",
       "      <td>cp activate wasd neuronet approach asian popul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>classifier consensus system approach credit sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6212</th>\n",
       "      <td>second order cone program formulation nonparal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>sequential fuzzy cluster base dynamic fuzzy ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>daddy car artificial intelligence creative too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>unconventional cognitive enhancement option ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>technological unemployment approximation latin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>tital asynchronous multiplayer shooter procedu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6218 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              abstracts\n",
       "0     human machine interaction facial expression re...\n",
       "1     rule base fuzzy cognitive map natural language...\n",
       "2     fog compute architecture healthcare wireless p...\n",
       "3     argumentation knowledge representation conflic...\n",
       "4     hydrothermal coordination power system scale i...\n",
       "...                                                 ...\n",
       "6213  sequential fuzzy cluster base dynamic fuzzy ne...\n",
       "6214  daddy car artificial intelligence creative too...\n",
       "6215  unconventional cognitive enhancement option ad...\n",
       "6216  technological unemployment approximation latin...\n",
       "6217  tital asynchronous multiplayer shooter procedu...\n",
       "\n",
       "[6218 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YG1-O4D26irL"
   },
   "source": [
    "#### Option B - Load keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "a7qJSz6l6mVt",
    "outputId": "e65d72cb-8ee9-49ac-cab4-9ff5c0231ca4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6546/6546 [00:00<00:00, 8418.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique tokens: 52365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "directory = datapath+'LDA/'\n",
    "file_name = period+' top_90-percentile_keywords_terms.csv'\n",
    "corpus = pd.read_csv(directory+file_name)\n",
    "corpus = corpus.fillna('this_is_null')\n",
    "corpus_tokens = []\n",
    "for idx,row in tqdm(corpus.iterrows(),total=corpus.shape[0]):\n",
    "    for token in row.values.tolist():\n",
    "        if token != 'this_is_null': \n",
    "            corpus_tokens.append(token) \n",
    "del corpus\n",
    "print(\"\\nNumber of unique tokens:\",len(corpus_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YXZPTZrKjhr"
   },
   "source": [
    "#### Option C - Load author keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "hq2HreIeKqP0",
    "outputId": "031b660b-100c-40b7-a563-b556d1df77d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1376/1376 [00:00<00:00, 9769.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique tokens: 1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "directory = datapath+'Author keywords - 29 Oct 2019/'\n",
    "file_name = period+' keyword frequency'\n",
    "corpus = pd.read_csv(directory+file_name,names=['keyword','frequency'])\n",
    "corpus = corpus.fillna('this_is_null')\n",
    "threshold = np.percentile(corpus['frequency'].values,percentile)\n",
    "corpus = corpus[corpus['frequency']>threshold]\n",
    "\n",
    "corpus_tokens = []\n",
    "for idx,row in tqdm(corpus.iterrows(),total=corpus.shape[0]):\n",
    "    if row['keyword'] != 'this_is_null': \n",
    "        corpus_tokens.append(row['keyword']) \n",
    "print(\"\\nNumber of unique tokens:\",len(corpus_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqlZHLo1e40r"
   },
   "source": [
    "## Facebook Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeC8SkXPkKjx"
   },
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hv3ACHBtexEI"
   },
   "outputs": [],
   "source": [
    "fb_model_address = datapath+'/FastText-crawl-300d-2M-subword/crawl-300d-2M-subword.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "w6K74cHMkKnn",
    "outputId": "640b9a1b-8888-4e67-b927-a1f803bcd589"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model(fb_model_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2648m7e8kk0n"
   },
   "source": [
    "#### Get embeddings\n",
    "\n",
    "*   Save to dictionary and json\n",
    "*   This takes much less space on disk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Mq87DiZxVvY"
   },
   "source": [
    "##### No n-gram handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RiJcbZqHkkLl",
    "outputId": "23f58666-ecbc-4c78-f2e8-84fa11b58948"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:00<00:00, 337.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save in a dict\n",
    "output_dict = {}\n",
    "comment_embedding = ''\n",
    "for token in tqdm(corpus_tokens[:],total=len(corpus_tokens[:])):\n",
    "    output_dict[token] = str(model.get_word_vector(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOMUto5AxVDy"
   },
   "source": [
    "##### Manual n-gram handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F4UJAF3exSLm",
    "outputId": "65624796-56fb-468e-b923-3ff5468369f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:00<00:00, 3792.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save in a dict\n",
    "comment_embedding = 'average_manual '\n",
    "output_dict = {}\n",
    "for token in tqdm(corpus_tokens[:],total=len(corpus_tokens[:])):\n",
    "    token_split = token.split(' ')\n",
    "    if len(token_split) > 0:\n",
    "        tmp_vector_grams = []\n",
    "        for item in token_split:\n",
    "            tmp_vector_grams.append(model.get_word_vector(item))\n",
    "        output_dict[token] = str(list(np.array(tmp_vector_grams).mean(axis=0)))\n",
    "    else:\n",
    "        output_dict[token] = str(model.get_word_vector(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8nMUTU0xXo8"
   },
   "source": [
    "##### Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJk-lqjemSky"
   },
   "outputs": [],
   "source": [
    "# Save embeddings to disk\n",
    "with open(directory+'vectors/100D/FastText vector '+comment_embedding+period+'.json', 'w') as json_file:\n",
    "    json.dump(output_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXkwEnj4lnJi"
   },
   "source": [
    "#### Get embeddings (alternative) : \n",
    "\n",
    "*   save to a list instead of a dicktionary and csv\n",
    "*   Will have many redundant words in it and will take lots of disk space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GndJ3Q1OlnSy"
   },
   "outputs": [],
   "source": [
    "# Save in a list\n",
    "batches = 1000\n",
    "batch_size = len(corpus_tokens)/batches\n",
    "\n",
    "for step in tqdm(range(batches),total=batches):\n",
    "    batch_tokens = corpus_tokens[int(step*batch_size):int((step+1)*batch_size)]\n",
    "    corpus_vectors = [model.get_word_vector(x) for x in batch_tokens]\n",
    "    corpus_vectors = pd.DataFrame(corpus_vectors)\n",
    "    corpus_vectors['tokens'] = batch_tokens\n",
    "\n",
    "    # Save embeddings to disk\n",
    "    with open(directory+'vector '+period,'a') as f:\n",
    "        corpus_vectors.to_csv(f,index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38Xcww-Mfdaj"
   },
   "source": [
    "## Gensim Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPd9g4E4fgTi"
   },
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06depR4llpmB"
   },
   "source": [
    "Load gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_UYlrcCfgxw"
   },
   "outputs": [],
   "source": [
    "gensim_model_address = datapath+'FastText Models/50D w1/fasttext-scopus-2.2-million_docs-gensim 50D-w1.model'\n",
    "model = fasttext_gensim.load(gensim_model_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gx1x_twuQCbQ"
   },
   "outputs": [],
   "source": [
    "gensim_model_address = datapath+'FastText Models/50D/fasttext-scopus_wos-merged-310k_docs-gensim 50D.model'\n",
    "model = fasttext_gensim.load(gensim_model_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q18gRbrW3mvO"
   },
   "outputs": [],
   "source": [
    "gensim_model_address = 'drive/My Drive/Data-Permenant/FastText-crawl-300d-2M-subword/crawl-300d-2M-subword.bin'\n",
    "model = gensim.models.fasttext.load_facebook_model(gensim_model_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XhKlmoX6gPE-"
   },
   "source": [
    "Simple Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7oeEkj_gNLg"
   },
   "outputs": [],
   "source": [
    "print('intelligence' in model.wv.vocab)\n",
    "print(model.similarity(\"anns\", \"ann\"))\n",
    "print(model.most_similar(['eye','vision','processing'], ['computer']))\n",
    "print(model.wmdistance(['stop', 'word', 'removed', 'tokens', 'of', 'sentence 1'], ['stop word removed tokens of sentence 2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rCuEFwIMbND_",
    "outputId": "038b21bb-96b1-45fc-d513-1939d1671df4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33358505368232727"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get distance of two words\n",
    "from scipy import spatial,sparse,sign\n",
    "vec_a = model.wv['']\n",
    "vec_b = model.wv['fpga']\n",
    "distance_tmp = spatial.distance.cosine(vec_a, vec_b)\n",
    "similarity_tmp = 1 - distance_tmp\n",
    "similarity_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "iPioY7Lj7BOP",
    "outputId": "8f170cbd-4949-4325-cb12-26ecd7164c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.25525   ,  0.03749213,  1.8276842 , -3.1528432 , -3.3440664 ,\n",
       "        0.66207427,  1.0964861 , -2.038055  ,  3.0331683 , -2.1755521 ,\n",
       "        2.1063838 ,  1.6578307 ,  1.3311137 , -2.030598  , -0.69794494,\n",
       "        2.6208954 ,  1.9154872 ,  1.6715113 ,  0.23561044, -0.50721526,\n",
       "        3.1775064 , -2.069317  , -2.4310536 , -1.8514946 ,  1.3029549 ,\n",
       "        3.482592  , -2.1535952 ,  1.078043  , -3.8000522 ,  0.08382007,\n",
       "       -0.6016187 ,  3.3550935 ,  2.5037699 , -2.8812122 , -0.11693893,\n",
       "       -0.51311666,  3.1224    ,  0.46978405, -0.4427654 , -2.5400903 ,\n",
       "        2.0880878 ,  3.123557  ,  0.8703581 , -1.0431769 , -2.8512125 ,\n",
       "        2.2627175 ,  1.0080537 ,  0.1098367 ,  1.5881126 , -1.870272  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['artificial intelligence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqUSjLRy_isH"
   },
   "outputs": [],
   "source": [
    "(model.wv['artificial']+model.wv['intelligence'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0gnOxud_m4H"
   },
   "outputs": [],
   "source": [
    "model.wv['artificial_intelligence']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5516KiWbelyF"
   },
   "source": [
    "#### Compare vectors to ACM categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AxNRKUidrCk"
   },
   "outputs": [],
   "source": [
    "AI_categories = [\n",
    "              'Artificial Intelligence Applications - Expert Systems',\n",
    "              'Automatic Programming',\n",
    "              'Deduction - Theorem Proving',\n",
    "              'Knowledge Representation Formalisms - Knowledge Representation Methods',\n",
    "              'Programming Languages - Software',\n",
    "              'Learning',\n",
    "              'Natural Language Processing',\n",
    "              'Problem Solving - Control Methods - Search',\n",
    "              'Robotics',\n",
    "              'Vision - Scene Understanding',\n",
    "              'Distributed Artificial Intelligence',\n",
    "              'ARTIFICIAL INTELLIGENCE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QeWKP-k1qpy"
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "              'Natural language processing - Information extraction - Machine translation - Discourse, dialogue  pragmatics - Natural language generation - Speech recognition - Lexical semantics - Phonology / morphology',\n",
    "              'Knowledge representation reasoning - Description logics - Semantic networks Nonmonotonic default reasoning  belief revision - Probabilistic reasoning - Vagueness fuzzy logic - Causal reasoning  diagnostics - Temporal reasoning - Cognitive robotics - Ontology engineering - Logic programming answer set programming - Spatial  physical reasoning - Reasoning about belief  knowledge',\n",
    "              'Planning  scheduling - Planning for deterministic actions - Planning under uncertainty - Multi-agent planning - Planning  abstraction  generalization - Robotic planning - Evolutionary robotics',\n",
    "              'Search methodologies - Heuristic function construction - Discrete space search - Continuous space search - Randomized search - Game tree search - Abstraction  micro-operators - Search with partial observations - ',\n",
    "              'Control methods - Robotic planning - Evolutionary robotics - Computational control theory - Motion path planning',\n",
    "              'Philosophical theoretical foundations artificial intelligence - Cognitive science - Theory mind',\n",
    "              'Distributed artificial intelligence - Multi agent systems - Intelligent agents - Mobile agents - Cooperation  coordination',\n",
    "              'Computer vision - Biometrics - Scene understanding - Activity recognition  understanding - Video summarization - Visual content based indexing  retrieval - Visual inspection - Vision for robotics - Scene anomaly detection - Image  video acquisition - Camera calibration - Epipolar geometry - Computational photography - Hyperspectral imaging - Motion capture - 3D imaging - Active vision - Image representations - Shape representations - Appearance  texture - Hierarchical representations - Computer vision problems - Interest point  salient region detections - Image segmentation  - Video segmentation - Shape inference - Object detection - Object recognition - Object identification - Tracking - Reconstruction - Matching',\n",
    "              \n",
    "              'Learning paradigms - Supervised learning - Ranking - Learning to rank - Supervised learning  classification - Supervised learning  regression - Structured outputs - Cost sensitive learning - Unsupervised learning - Cluster analysis - Anomaly detection - Mixture modeling - Topic modeling - Source separation - Motif discovery - Dimensionality reduction  manifold learning - Reinforcement learning - Sequential decision making - Inverse reinforcement learning - Apprenticeship learning - Multi-agent reinforcement learning - Adversarial learning - Multi-task learning - Transfer learning - Lifelong machine learning - Learning under covariate shift',\n",
    "              'Learning settings - Batch learning - Online learning settings - Learning from demonstrations - Learning from critiques - Learning from implicit feedback - Active learning settings - Semi supervised learning settings',\n",
    "              'Machine learning approaches - Classification  regression trees - Kernel methods - Support vector machines - Gaussian processes - Neural networks - Logical  relational learning - Inductive logic learning - Statistical relational learning - Learning in probabilistic graphical models - Maximum likelihood modeling - Maximum entropy modeling - Maximum a posteriori modeling - Mixture models - Latent variable models - Bayesian network models - Learning linear models - Perceptron algorithm - Factorization methods - Non-negative matrix factorization - Factor analysis - Principal component analysis - Canonical correlation analysis - Latent Dirichlet allocation - Rule learning - Instance-based learning - Markov decision processes -  Markov decision processes - Stochastic games - Learning latent representations - Deep belief networks - Bio inspired approaches - Artificial life - Evolvable hardware - Genetic algorithms - Genetic programming - Evolutionary robotics - Generative  developmental approaches',\n",
    "              'Machine learning algorithms - Dynamic programming Markov decision processes - Value iteration - Q learning - Policy iteration - Temporal difference learning - Approximate dynamic programming methods - Ensemble methods - Boosting - Bagging - Spectral methods - Feature selection - Regularization',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-rtaQ7KbfQ_y",
    "outputId": "cd8e2034-6f91-44a3-f38d-1073e8cd6bda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.2585297, -1.09474, -0.51740396, -1.5583799, -1.277385, 1.2230147, 3.6439853, -1.6600533, 1.4912666, -2.3865879, 1.2189151, 0.5719612, 2.7518144, -2.781408, -2.061385, 2.1494553, 1.0412952, 2.237492, 0.14161092, -1.4961629, 1.8666816, -1.0945007, -0.40818986, -1.4722152, -0.20459145, 2.328488, -0.7185293, 0.63060343, -2.3967595, -1.0597452, 1.1229446, 1.805113, 1.015998, -2.1873384, -0.12749422, -0.016316757, 1.9769442, 0.9840427, -1.7754203, -3.5659814, 3.1010442, 2.0076227, 0.61076725, -0.32515174, -3.6688373, -1.054969, 2.3143127, 0.7147262, 1.1658139, 0.8725452], [-4.7960773, -1.7704331, -0.17159314, -1.5654887, -1.696463, 1.3633636, 2.3642745, -0.60040635, 1.4829278, -2.4751508, 1.0201765, 0.6441909, 2.688061, -2.4529297, 0.47901928, 2.3566878, 1.1981105, 0.46998572, 0.58817506, -0.64123666, 2.3364296, -2.3828585, 0.27646962, -0.96989816, 0.2530441, 1.0085167, -0.6223591, 0.35445678, -2.2382672, -0.57872456, 1.659824, 2.0099118, 2.595362, -0.9997726, -0.09018091, 0.8816102, 2.4655735, 0.8050124, -1.1530598, -3.0836341, 2.7684937, 1.0073061, 0.00575616, -0.57786924, -3.2156136, 0.95476097, 1.5965384, 0.76067203, 1.2837223, -0.3671839], [-4.783248, -2.4654036, 1.8282199, -3.2524014, -2.9422593, 0.47818545, 1.1319468, -0.48558038, 1.7362764, -1.7564304, 0.1713893, -1.0876645, 0.59644246, -0.96832526, 1.0853738, 3.143952, 2.3456964, -0.073322356, 0.8511666, -1.0623292, 2.6982129, -1.3787885, -1.641756, -2.0564864, -0.35710108, 1.4279834, -0.19134875, 1.7257166, -3.5816538, -0.40132627, 1.0557052, 2.7683246, 1.7407539, -1.9736162, 1.3690635, 0.73754, 2.0931156, 1.2272679, -0.3931911, -3.7137809, 4.2403607, 2.0456743, -1.8043844, -1.375812, -3.5201724, 0.74615204, 2.9523208, -0.55889595, -0.4305116, -0.6135682], [-2.6682758, -2.0906448, 0.3702082, -1.763951, -1.3056281, 1.2989495, 1.6341537, -0.018645708, 0.4660442, -1.3926327, 0.26077935, -0.09793859, 0.6407897, -1.0905774, -0.19085528, 3.055617, 1.3357424, 0.74421144, 0.957384, 0.028282428, 1.0109622, -0.707255, -0.27613002, -2.3247027, -0.9078487, 0.6687898, -0.690248, 1.9313891, -1.7434508, -1.0016263, 1.1569431, 1.4039564, 1.6583602, -1.4211533, 0.843102, 0.17694066, 1.8566834, -0.081796244, -0.5027641, -2.5389442, 2.543816, 1.2051241, -0.22449279, -0.8894108, -2.199338, -0.045534465, 0.24319553, -0.8911654, -0.7639756, -0.085744336], [-4.418727, -1.419803, 1.5708158, -2.6987824, -2.4854412, 0.5691688, 0.043044917, -0.27786833, 2.7932034, -1.7903156, 0.24949542, -0.038802195, 1.4238329, -1.541058, 0.14870362, 3.6138458, 2.4389935, 0.7642016, 1.1146837, -0.7245118, 2.6403756, -2.103103, -1.2469227, -2.0934734, -0.18935119, 1.6391281, -0.58698606, 1.9130386, -2.9331021, -0.7162676, 0.6673344, 3.0299964, 1.6199672, -2.2228365, 0.91334563, 0.24507749, 2.2792773, 0.3434165, -0.28254068, -3.0037558, 3.4233003, 2.5353255, -1.0407612, -0.71328354, -2.9894512, 0.39342391, 2.1154754, -0.6439582, -0.8723666, -0.69555795], [-3.6296988, -0.30504742, 0.021212062, -0.6736031, -1.7472433, 0.4192197, 1.2212005, -0.33318245, 2.3278158, -3.0614612, 1.4572011, 1.3329434, 3.8018093, -2.5337079, 0.4183, 3.3435352, 1.8631892, 1.0934873, 0.9327049, -0.9528741, 4.335353, -2.124141, -0.84434754, -1.9663016, 1.3545097, 2.332329, -0.03459015, 0.26926598, -1.432001, -0.26175267, -0.04326086, 2.207326, 3.1373577, -2.5924451, 0.79329664, 0.15286009, 3.5641758, 1.3748256, -1.4313527, -2.0387158, 0.45870805, 1.7892777, 0.7697367, -1.0888867, -2.8586924, 0.9864697, 1.1540154, -0.79008555, 3.1888273, -0.36340716], [-4.7498655, -2.0082538, 2.0650477, -2.6538336, -2.7813652, -0.2219172, 0.7528862, -0.7714873, 2.1804569, -1.7407357, 2.6121962, -0.9179781, 0.45030347, -1.7619938, 0.644618, 2.9984355, 1.8543806, 0.49087667, -1.310003, -1.2778642, 2.9742165, -0.60248816, -0.6721307, -1.7180697, 0.8103083, 3.1431892, -0.65900195, 1.890321, -3.1091056, -0.83834237, 0.22258794, 1.9165051, 1.5989912, -2.121817, 0.98958856, 0.33478117, 2.656167, 1.47242, 0.2738269, -3.0141346, 2.506883, 2.2542617, -1.8579614, -1.4157169, -2.2660065, 1.4739611, 1.986954, 0.2688377, -0.01116084, -0.7620956], [-3.8344402, -1.7627443, 0.013482263, -2.1556933, -1.7925524, 0.5110146, 2.7021735, -0.42457277, 1.7370346, -2.0547361, 0.58410996, -0.20980693, 2.604441, -1.3165913, -2.4578385, 3.5423813, 1.8524952, 1.6111225, 1.1050096, -1.8564557, 1.8394259, -1.8160945, -0.87464285, -1.9847978, -0.73219126, 2.048561, -2.068477, 2.7930079, -2.8351939, -0.62764347, 1.238038, 1.5283931, 0.47022444, -1.8407842, 0.7971539, 0.006729732, 2.448745, 0.88317794, -0.9530853, -3.3691823, 3.385877, 2.2737489, 1.5180569, 0.5125543, -2.8273292, -0.6604535, 3.147259, 1.0307336, -0.8378401, 0.48748377], [-4.803697, -1.6953143, 0.08243193, -2.7868576, -2.0559573, 2.293871, 2.5148377, -0.9782568, 1.3664638, -2.1174574, 1.8977991, -1.1527096, 1.0931118, -1.9012688, -0.6044156, 3.277232, 2.8219721, 0.6098037, -0.1970612, -1.9165957, 0.5713004, -1.1373634, -1.65581, -1.6858883, -1.1937876, 1.0006716, 0.09968073, 3.0323098, -3.7464862, 1.0631689, 0.57072383, 2.5665638, 0.49634123, -1.5698158, 0.793332, 0.3296176, 2.1543145, 0.988778, -0.8270112, -3.4312904, 2.691986, 2.053164, 1.0331227, -0.79652774, -3.6579661, 0.89351505, 1.0108926, 0.14591649, 0.24157651, -0.3091852], [-4.209945, -1.478514, -0.65360236, -1.3783714, -1.8534892, 3.2209125, 1.6276795, -0.23348632, 1.5915459, -1.4042844, 2.5756416, -0.7158973, 0.6250525, -1.7714843, -0.785086, 3.0324762, 3.3969445, 0.16155249, -0.36199412, -1.5491321, 0.7203293, -1.2083378, -0.15985551, -0.7954497, -1.4161118, 0.5783136, 0.24014375, 2.5570612, -2.4276257, 0.17151444, -0.32569277, 2.552733, 0.36257836, -1.5491463, 0.84296405, 0.37183225, 1.6477425, -0.04394825, -0.98846924, -2.1261923, 2.3017104, 1.5071672, 1.1247743, -2.111504, -3.1492555, 1.1366179, -0.5207402, -0.08834131, -0.002603922, 0.36255994], [-4.456132, -1.2375709, -0.060436487, -2.3262725, -1.5555788, 2.0290685, 2.1207979, -0.882367, 1.1406393, -2.1224058, 1.2132982, -0.7152811, 1.6820112, -2.1260521, -0.29163978, 3.8474853, 0.966945, 0.3466788, 0.27146608, -1.5148053, 0.41290393, -0.8747698, -1.4122522, -2.3614087, -1.1230488, 0.5673031, -0.25742036, 2.0600169, -2.3180704, 0.43655294, 0.39970943, 1.9141394, 1.0064878, -0.93134433, 0.5157056, -0.5070268, 2.3600667, 0.6129178, -0.55783105, -2.9124885, 2.026174, 1.5843923, 0.22606745, -0.513916, -3.4471755, 0.71103764, -0.028376233, 0.14374025, 0.2138857, -0.35969982], [-4.2178745, -1.4500127, 0.4737355, -3.1575625, -2.104847, 2.710899, 3.159836, -0.4343515, 0.928192, -2.8238966, 1.3814604, -1.0762248, 1.8243719, -2.1669593, -0.91299856, 4.3921742, 2.711184, 0.70554423, 0.39368823, -1.8234388, 0.099572524, -0.69179505, -0.965667, -3.43647, -1.9561361, 0.8922539, -0.62991774, 3.2562766, -3.4762852, 0.59666866, 0.14012648, 2.264789, 0.8790767, -1.3577005, 0.4756403, -0.35558546, 3.0121443, 0.12617694, -0.5292348, -3.7549527, 3.140975, 1.8866202, 0.7874215, -0.6871964, -4.3557415, 0.112307295, 0.04104868, -0.51128495, -0.5597852, -0.55689055]]\n"
     ]
    }
   ],
   "source": [
    "AI_vectors = []\n",
    "labels = []\n",
    "for item in categories:\n",
    "    vector_tmp = []\n",
    "    label = item.split('-')[0]\n",
    "    for phrase in item.split('-'):\n",
    "        phrase = phrase.lower().strip()\n",
    "        # print(phrase)\n",
    "        vector_tmp.append(model.wv[phrase])\n",
    "    # print('---')\n",
    "    AI_vectors.append(list(np.array(vector_tmp).mean(axis=0)))\n",
    "    labels.append(label)\n",
    "print(AI_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brCodssfgEgt"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(AI_vectors).to_csv(datapath+'FastText doc clusters - SIP/50D/classification/ACM_classifications_vectors')\n",
    "pd.DataFrame(labels,columns=['label']).to_csv(datapath+'FastText doc clusters - SIP/50D/classification/ACM_classifications_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMAHWCgX6kEz"
   },
   "source": [
    "### Get Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8LPLO5z4cER3"
   },
   "source": [
    "##### No n-gram handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lP8pYSjf6kiR",
    "outputId": "3293d0e4-ff19-437d-def6-b56259717fbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3184174/3184174 [27:52<00:00, 1903.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save in a dict\n",
    "comment_embedding = ''\n",
    "output_dict = {}\n",
    "for token in tqdm(corpus_tokens[:],total=len(corpus_tokens[:])):\n",
    "    output_dict[token] = str(model.wv[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AGLF7jepcI83"
   },
   "source": [
    "##### Manual n-gram handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w9cb-KpAcPWJ",
    "outputId": "4f2e771b-0fb9-487f-c7db-b11e3da36156"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:00<00:00, 10574.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save in a dict\n",
    "comment_embedding = 'average_manual '\n",
    "output_dict = {}\n",
    "for token in tqdm(corpus_tokens[:],total=len(corpus_tokens[:])):\n",
    "    token_split = token.split(' ')\n",
    "    if len(token_split) > 0:\n",
    "        tmp_vector_grams = []\n",
    "        for item in token_split:\n",
    "            tmp_vector_grams.append(model.wv[item])\n",
    "        output_dict[token] = str(list(np.array(tmp_vector_grams).mean(axis=0)))\n",
    "    else:\n",
    "        output_dict[token] = str(model.wv[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wk6CJa6pcQC-"
   },
   "source": [
    "##### Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4wRDXMX6tBH"
   },
   "outputs": [],
   "source": [
    "# Save embeddings to disk\n",
    "with open(directory+'/FastText vector with n-grams '+comment_embedding+period+'.json', 'w') as json_file:\n",
    "    json.dump(output_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ohPXzf8mKUxQ",
    "outputId": "4588f6a5-d865-48bb-fb40-d90033bc007a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive/My Drive/Data/corpus/improved_copyr_lemmatized_stopwords_removed_thesaurus_n-grams/\n"
     ]
    }
   ],
   "source": [
    "print(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yYjO-JQBLE3"
   },
   "source": [
    "### Get Doc Embeddings (SIF)\n",
    "\n",
    "It is not recommended to perform this on cloud, as it is not process intesive, yet takes too long depending on the doc-count. It might take over 30 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hp1fP9z4xUGX"
   },
   "source": [
    "Make a probability dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "buSIQtoWVnOz"
   },
   "outputs": [],
   "source": [
    "corpus_tokens_s = pd.Series(corpus_tokens)\n",
    "corpus_tokens_probabilities = (corpus_tokens_s.groupby(corpus_tokens_s).transform('count') / len(corpus_tokens_s)).values\n",
    "corpus_tokens_probabilities = pd.DataFrame(corpus_tokens_probabilities)\n",
    "corpus_tokens_probabilities['tokens'] = corpus_tokens_s\n",
    "corpus_tokens_probabilities.columns = ['probability','token']\n",
    "corpus_tokens_probabilities = corpus_tokens_probabilities.groupby('token').mean()\n",
    "corpus_tokens_probabilities = corpus_tokens_probabilities.reset_index()\n",
    "corpus_tokens_probabilities.columns = ['token','probability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qu51jQbo9QE6"
   },
   "source": [
    "Get vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "72BAU9Jm9PwE",
    "outputId": "ff5de028-3fe9-4881-cf8e-fc822c590a36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21794/21794 [00:00<00:00, 139978.84it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "for token in tqdm(corpus_tokens_probabilities['token'],total=corpus_tokens_probabilities.shape[0]):\n",
    "    vectors.append(model.wv[token])\n",
    "corpus_tokens_probabilities['vector'] = vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Y9rI72IxZal"
   },
   "source": [
    "Calculate weighted average vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4WwJtQqABN8w",
    "outputId": "51cd00a8-a55c-4119-8abb-e04e068e5b61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6218/6218 [1:16:11<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "a = 1e-3\n",
    "embedding_size = 50\n",
    "\n",
    "doc_set = []\n",
    "for doc in tqdm(corpus['abstracts'].values.tolist(),total=len(corpus['abstracts'].values.tolist())):\n",
    "    vs = np.zeros(embedding_size)  # add all word2vec values into one vector for the sentence\n",
    "    doc_length = len(doc.split())\n",
    "#     print(doc.split())\n",
    "    for word in doc.split():\n",
    "        a_value = a / (a + corpus_tokens_probabilities[corpus_tokens_probabilities['token']==word]['probability'].values.tolist()[0])  # smooth inverse frequency, SIF\n",
    "        vs = np.add(vs, np.multiply(a_value, corpus_tokens_probabilities[corpus_tokens_probabilities['token']==word]['vector'].values.tolist()[0]))  # vs += sif * word_vector\n",
    "\n",
    "    vs = np.divide(vs, doc_length)  # weighted average\n",
    "    doc_set.append(vs)  # add to our existing re-calculated set of sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6L6EqReXxgPX"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-sr_ytww9emi"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(doc_set).to_csv(datapath+'Document Embedding/50D/'+file_name,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_m00tKKkKNG"
   },
   "source": [
    "# Train on a large Scopus corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nz7pfl9d6R9o"
   },
   "source": [
    "#### Load Corpus Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VuO0J8oxkKWz"
   },
   "outputs": [],
   "source": [
    "sentence_corpus = pd.read_csv(datapath+'corpus/AI ALL/1900-2019 corpus sentences abstract-title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYHEYxwpEgCi"
   },
   "source": [
    "#### Preprocess and prepare corpus for FastText training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tkqrGJ3cEgnX",
    "outputId": "0b5441c0-1785-4a1e-83e7-6b6c995d31b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13307816/13307816 [1:54:08<00:00, 1943.10it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "with open(datapath+'corpus/AI ALL/1900-2019 corpus sentences abstract-title further processed.csv', 'w') as f:\n",
    "    for index,row in tqdm(sentence_corpus.iterrows(),total=sentence_corpus.shape[0]):\n",
    "        sentence = row['sentence']\n",
    "        sentence = re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",sentence)\n",
    "        sentence = word_tokenize(sentence)\n",
    "        sentence = [word for word in sentence if not word in punkts] \n",
    "        sentence = [lemmatizer.lemmatize(word) for word in sentence]\n",
    "        # sentences.append(sentence)\n",
    "        f.write(\"%s\\n\" % ' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQHwYepMdKFc"
   },
   "source": [
    "#### Save sentences to disk for future use -- Not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJZ0UwdhdOlp"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([' '.join(words) for words in sentences],columns=['sentences']).to_csv(\n",
    "    datapath+'corpus/AI ALL/1900-2019 corpus sentences abstract-title further processed.csv',\n",
    "    header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-j6H5hsfu8p0"
   },
   "source": [
    "#### Load pre-processed sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yLHxqzOPvCdV",
    "outputId": "9171ddac-0f5d-4dfe-8bc9-99e563071495"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13230009/13230009 [28:30<00:00, 7736.00it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_corpus = pd.read_csv(datapath+'corpus/AI ALL/1900-2019 corpus sentences abstract-title further processed.csv',delimiter=\";;;\")\n",
    "sentence_corpus.columns = [\"sentences\"]\n",
    "sentences = []\n",
    "sentence_corpus = sentence_corpus.fillna('')\n",
    "for index,row in tqdm(sentence_corpus.iterrows(),total=sentence_corpus.shape[0]):\n",
    "    sentences.append(row['sentences'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "UA83SDYjwfrO",
    "outputId": "62a9447a-3b75-40ef-bd4a-2910968b284f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>circuit sequential circuit or vlsi chip realiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the design of efficient hardware is a fundamen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>because of the large cost for the physical con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for these purpose data structure for boolean f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the corresponding state of the art data struct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>efficient algorithm for the operation on obdds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a generalized data structure called graph-driv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the new data structure allows for many importa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>efficient algorithm for the operation on graph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>consider a finite graph g v e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences\n",
       "0  circuit sequential circuit or vlsi chip realiz...\n",
       "1  the design of efficient hardware is a fundamen...\n",
       "2  because of the large cost for the physical con...\n",
       "3  for these purpose data structure for boolean f...\n",
       "4  the corresponding state of the art data struct...\n",
       "5  efficient algorithm for the operation on obdds...\n",
       "6  a generalized data structure called graph-driv...\n",
       "7  the new data structure allows for many importa...\n",
       "8  efficient algorithm for the operation on graph...\n",
       "9                      consider a finite graph g v e"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_corpus.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-9A4hbD7xwV"
   },
   "source": [
    "### Train Fasttext - Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MYfn-ZQfhed1"
   },
   "source": [
    "#### Load a model to continue training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Bnu7_aMhu-A"
   },
   "source": [
    "* If want to continue training, run this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7eHrQg_g2ej"
   },
   "outputs": [],
   "source": [
    "model = load(gensim_model_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s07ymd4xhtWh"
   },
   "outputs": [],
   "source": [
    "model.build_vocab(sentences, update=True)\n",
    "model.train(sentences, total_examples=len(sentences), epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9LWfxerh2DI"
   },
   "source": [
    "* Otherwise run this section\n",
    "\n",
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsDmFFxp7yJa"
   },
   "outputs": [],
   "source": [
    "model = fasttext_gensim(min_n=3, max_n=6, size=15, window=5, min_count=1, seed = 50)\n",
    "model.build_vocab(sentences=sentences)\n",
    "model.train(sentences=sentences, total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqV_noKRcD4b"
   },
   "outputs": [],
   "source": [
    "fname = \"datapath+Models/fasttext-scopus-2.2-million_docs-gensim 15D.model\"\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3vrtHdqHy-K"
   },
   "outputs": [],
   "source": [
    "model = fasttext_gensim(min_n=3, max_n=6, size=50, window=5, min_count=1, seed = 50)\n",
    "model.build_vocab(sentences=sentences)\n",
    "model.train(sentences=sentences, total_examples=len(sentences), epochs=10)\n",
    "fname = datapath+\"Models/fasttext-scopus-2.2-million_docs-gensim 50D.model\"\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g75Pt__ZH4RZ"
   },
   "outputs": [],
   "source": [
    "model = fasttext_gensim(min_n=3, max_n=6, size=100, window=5, min_count=1, seed = 50)\n",
    "model.build_vocab(sentences=sentences)\n",
    "model.train(sentences=sentences, total_examples=len(sentences), epochs=10)\n",
    "fname = datapath+\"Models/fasttext-scopus-2.2-million_docs-gensim 50D.model\"\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mnTG0yUGiqxw"
   },
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVJoU_sLiw2E"
   },
   "outputs": [],
   "source": [
    "similarities = model.wv.most_similar(positive=['logic','fuzzy','expert'],negative=['deep','neural','network','cnn','ann'])\n",
    "most_similar = similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JaKS52YSDcup",
    "outputId": "c4257bf2-6134-4a85-df40-d7696a731c57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mam-rnn', 0.9763791561126709)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkokDJdHjEFz"
   },
   "outputs": [],
   "source": [
    "not_matching = model.wv.doesnt_match(\"human computer interface tree\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7fOp26djDYk7",
    "outputId": "3fca5ff0-ac5a-464e-ddf8-4662385b6c82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tree'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x7RJl89QjMhl"
   },
   "outputs": [],
   "source": [
    "sim_score = model.wv.similarity('computer', 'human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DtlAXvqWDWo4",
    "outputId": "639a0234-75f9-4fec-c4ee-09d607516050"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7571839"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "xWLLBs8UBRwy",
    "outputId": "836cc23e-4ba9-4dfd-dfaa-21f5dd09f25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2783480e+00 -4.2018552e+00  7.1276689e-01  4.2023015e+00\n",
      " -5.0359420e-03  4.4385982e+00  6.2421050e+00 -8.9032326e+00\n",
      "  1.7556003e+00  1.3425230e+00  9.4295764e-01 -4.4485557e-01\n",
      " -5.8648558e+00  2.6428668e+00 -1.2076639e+00]\n",
      "[  3.7072854   -3.616749     1.3040072    0.234361    -2.753659\n",
      "   7.528801    14.293305   -14.688236     5.3885765    6.496681\n",
      "   1.9917868    2.855616    -0.05153261   7.8660994   -2.22459   ]\n",
      "[  0.28606984  -6.971052    -0.9232919   11.48035      0.2561571\n",
      "   4.084776     2.4220266   -8.616226     0.94255084  -2.2498865\n",
      "   1.7112938   -3.370861   -12.577294    -1.1608386   -0.04991044]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['artificial intelligence'])\n",
    "print(model.wv['artificial'])\n",
    "print(model.wv['intelligence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sSZfjEMUyMc"
   },
   "source": [
    "### Train Fasttext - Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oK4N7jUqU1CJ"
   },
   "outputs": [],
   "source": [
    "sentences_joined = ' '.join(sentences)\n",
    "model = fasttext.train_unsupervised(sentences_joined, \"cbow\", minn=2, maxn=5, dim=50, epoch=10,lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLNquk0BaywP"
   },
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9i6detxZVMUQ"
   },
   "outputs": [],
   "source": [
    "model.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o13SRSefVFDD"
   },
   "outputs": [],
   "source": [
    "model.get_word_vector(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FvMFASYVNzs"
   },
   "outputs": [],
   "source": [
    "model.get_nearest_neighbors('asparagus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TH9Wdf5WV5F8"
   },
   "outputs": [],
   "source": [
    "model.get_analogies(\"intelligence\", \"math\", \"fuzzy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaDnem0pWcNw"
   },
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wjWeyw-Wbpi"
   },
   "outputs": [],
   "source": [
    "model.save_model(datapath+\"fasttext-scopus_wos-merged-310k_docs-facebook.ftz\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "r_m00tKKkKNG"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "fasttext_embedding.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
