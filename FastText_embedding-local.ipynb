{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sahandv/science_science/blob/master/FastText_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B43KQKxsZqK2"
   },
   "source": [
    "# FASTTEXT EMBEDDING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyakRMAwbUq2"
   },
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W9l5YuBnkKFB"
   },
   "source": [
    "### Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4sdVZl-kKI3"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import json\n",
    "import re\n",
    "\n",
    "# import fasttext\n",
    "from pyemd import emd\n",
    "from gensim.similarities import WmdSimilarity\n",
    "from gensim.models import FastText as fasttext_gensim\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sciosci.assets import keyword_assets as kw\n",
    "from sciosci.assets import generic_assets as sci\n",
    "from sciosci.assets import advanced_assets as aa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wu17lpjOg7F2"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "draRfEpf8A5L",
    "outputId": "21414a26-5e37-4bc2-fc4d-a5794a085eda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sahand/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sahand/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sahand/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "stops = ['a','an','we','result','however','yet','since','previously','although','propose','proposed','e_g','method',\n",
    "         'published_elsevier','b','v','problem','paper','approach','within','with','by','via','way','t','case','issue','level','area','system',\n",
    "         'work','discussed','seen','put','usually','take','make','author','versus','enables','result','research','design','based']\n",
    "punkts = [' ','','(',')','[',']','{','}','.',',','!','?','<','>','-','_',':',';','\\\\','/','|','&','%',\"'s\",\"`s\",'#','$','@','≅','=']\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = list(set(stopwords.words(\"english\")))+stops+punkts\n",
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iLK4cDhVkKbs"
   },
   "source": [
    "# Get embeddings from a pre-trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WhKPivNafWBf"
   },
   "source": [
    "### Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQEzlLSQ6g0E"
   },
   "outputs": [],
   "source": [
    "period = '2014-2016'\n",
    "percentile = 97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h6XYOAVzkKsR"
   },
   "source": [
    "#### Option A - Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PkWEF6DBkKzd",
    "outputId": "c44ff740-f959-4981-ab2b-6f79a2f2aea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1580225"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/home/sahand/Data/corpus/improved_copyr_thesaurus/n-grams/'\n",
    "file_name = period+' corpus abstract-title'\n",
    "corpus = pd.read_csv(directory+file_name,names=['abstracts'])\n",
    "corpus_tokens = [item for sublist in corpus['abstracts'].values.tolist() for item in sublist.split()]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YG1-O4D26irL"
   },
   "source": [
    "#### Option B - Load keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "a7qJSz6l6mVt",
    "outputId": "e65d72cb-8ee9-49ac-cab4-9ff5c0231ca4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6546/6546 [00:00<00:00, 8418.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique tokens: 52365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "directory = 'drive/My Drive/Data/LDA/'\n",
    "file_name = period+' top_90-percentile_keywords_terms.csv'\n",
    "corpus = pd.read_csv(directory+file_name)\n",
    "corpus = corpus.fillna('this_is_null')\n",
    "corpus_tokens = []\n",
    "for idx,row in tqdm(corpus.iterrows(),total=corpus.shape[0]):\n",
    "    for token in row.values.tolist():\n",
    "        if token != 'this_is_null': \n",
    "            corpus_tokens.append(token) \n",
    "del corpus\n",
    "print(\"\\nNumber of unique tokens:\",len(corpus_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2YXZPTZrKjhr"
   },
   "source": [
    "#### Option C - Load author keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "hq2HreIeKqP0",
    "outputId": "031b660b-100c-40b7-a563-b556d1df77d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1376/1376 [00:00<00:00, 9769.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique tokens: 1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "directory = 'drive/My Drive/Data/Author keywords - 29 Oct 2019/'\n",
    "file_name = period+' keyword frequency'\n",
    "corpus = pd.read_csv(directory+file_name,names=['keyword','frequency'])\n",
    "corpus = corpus.fillna('this_is_null')\n",
    "threshold = np.percentile(corpus['frequency'].values,percentile)\n",
    "corpus = corpus[corpus['frequency']>threshold]\n",
    "\n",
    "corpus_tokens = []\n",
    "for idx,row in tqdm(corpus.iterrows(),total=corpus.shape[0]):\n",
    "    if row['keyword'] != 'this_is_null': \n",
    "        corpus_tokens.append(row['keyword']) \n",
    "print(\"\\nNumber of unique tokens:\",len(corpus_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqlZHLo1e40r"
   },
   "source": [
    "## Facebook Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeC8SkXPkKjx"
   },
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hv3ACHBtexEI"
   },
   "outputs": [],
   "source": [
    "fb_model_address = 'drive/My Drive/Data-Permenant/FastText-crawl-300d-2M-subword/crawl-300d-2M-subword.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "w6K74cHMkKnn",
    "outputId": "640b9a1b-8888-4e67-b927-a1f803bcd589"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.load_model(fb_model_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2648m7e8kk0n"
   },
   "source": [
    "#### Get embeddings\n",
    "\n",
    "*   Save to dictionary and json\n",
    "*   This takes much less space on disk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Mq87DiZxVvY"
   },
   "source": [
    "##### No n-gram handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RiJcbZqHkkLl",
    "outputId": "23f58666-ecbc-4c78-f2e8-84fa11b58948"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:00<00:00, 337.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save in a dict\n",
    "output_dict = {}\n",
    "comment_embedding = ''\n",
    "for token in tqdm(corpus_tokens[:],total=len(corpus_tokens[:])):\n",
    "    output_dict[token] = str(model.get_word_vector(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOMUto5AxVDy"
   },
   "source": [
    "##### Manual n-gram handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F4UJAF3exSLm",
    "outputId": "65624796-56fb-468e-b923-3ff5468369f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:00<00:00, 3792.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save in a dict\n",
    "comment_embedding = 'average_manual '\n",
    "output_dict = {}\n",
    "for token in tqdm(corpus_tokens[:],total=len(corpus_tokens[:])):\n",
    "    token_split = token.split(' ')\n",
    "    if len(token_split) > 0:\n",
    "        tmp_vector_grams = []\n",
    "        for item in token_split:\n",
    "            tmp_vector_grams.append(model.get_word_vector(item))\n",
    "        output_dict[token] = str(list(np.array(tmp_vector_grams).mean(axis=0)))\n",
    "    else:\n",
    "        output_dict[token] = str(model.get_word_vector(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8nMUTU0xXo8"
   },
   "source": [
    "##### Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJk-lqjemSky"
   },
   "outputs": [],
   "source": [
    "# Save embeddings to disk\n",
    "with open(directory+'vectors/100D/FastText vector '+comment_embedding+period+'.json', 'w') as json_file:\n",
    "    json.dump(output_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IXkwEnj4lnJi"
   },
   "source": [
    "#### Get embeddings (alternative) : \n",
    "\n",
    "*   save to a list instead of a dicktionary and csv\n",
    "*   Will have many redundant words in it and will take lots of disk space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GndJ3Q1OlnSy"
   },
   "outputs": [],
   "source": [
    "# Save in a list\n",
    "batches = 1000\n",
    "batch_size = len(corpus_tokens)/batches\n",
    "\n",
    "for step in tqdm(range(batches),total=batches):\n",
    "    batch_tokens = corpus_tokens[int(step*batch_size):int((step+1)*batch_size)]\n",
    "    corpus_vectors = [model.get_word_vector(x) for x in batch_tokens]\n",
    "    corpus_vectors = pd.DataFrame(corpus_vectors)\n",
    "    corpus_vectors['tokens'] = batch_tokens\n",
    "\n",
    "    # Save embeddings to disk\n",
    "    with open(directory+'vector '+period,'a') as f:\n",
    "        corpus_vectors.to_csv(f,index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38Xcww-Mfdaj"
   },
   "source": [
    "## Gensim Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPd9g4E4fgTi"
   },
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06depR4llpmB"
   },
   "source": [
    "Load gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_UYlrcCfgxw"
   },
   "outputs": [],
   "source": [
    "gensim_model_address = '/home/sahand/Data/FastText Models/50D w1/fasttext-scopus-2.2-million_docs-gensim 50D-w1.model'\n",
    "model = fasttext_gensim.load(gensim_model_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XhKlmoX6gPE-"
   },
   "source": [
    "Simple Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "n7oeEkj_gNLg",
    "outputId": "fb6144c1-3338-42de-957c-ea95f3da6c28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.80139047\n",
      "[('bagha', 0.784936785697937), ('bagua', 0.7760497331619263), ('bagherzandi', 0.7488542795181274), ('bagaen', 0.7457777857780457), ('bagheria', 0.7434571385383606), ('baghi', 0.7406474351882935), ('bagana', 0.7358278632164001), ('bagci', 0.7353381514549255), ('kainji', 0.7331032156944275), ('we-lbv', 0.7320331335067749)]\n",
      "0.73269963\n",
      "25.106913131596503\n"
     ]
    }
   ],
   "source": [
    "print('intelligence' in model.wv.vocab)\n",
    "print(model.similarity(\"machine learning\", \"artificial intelligence\"))\n",
    "print(model.most_similar(positive=['baghdad', 'england'], negative=['london']))\n",
    "print(model.n_similarity(['neural network','deep learning'], ['ann']))\n",
    "print(model.wmdistance(['stop', 'word', 'removed', 'tokens', 'of', 'sentence 1'], ['stop word removed tokens of sentence 2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rCuEFwIMbND_",
    "outputId": "038b21bb-96b1-45fc-d513-1939d1671df4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7625598907470703"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get distance of two words\n",
    "from scipy import spatial,sparse,sign\n",
    "vec_a = (model.wv['machine']+model.wv['learning'])/2\n",
    "vec_b = (model.wv['artificial']+model.wv['intelligence'])/2\n",
    "distance_tmp = spatial.distance.cosine(vec_a, vec_b)\n",
    "similarity_tmp = 1 - distance_tmp\n",
    "similarity_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.801390528678894"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_a = model.wv[\"machine learning\"]\n",
    "vec_b = model.wv[\"artificial intelligence\"]\n",
    "distance_tmp = spatial.distance.cosine(vec_a, vec_b)\n",
    "similarity_tmp = 1 - distance_tmp\n",
    "similarity_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "iPioY7Lj7BOP",
    "outputId": "8f170cbd-4949-4325-cb12-26ecd7164c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45623803,  1.6125572 ,  1.7761922 , -0.7947932 , -5.7335396 ,\n",
       "        4.5503316 ,  2.6465545 , -1.6921854 ,  0.10005848,  2.6700506 ,\n",
       "       -2.770975  , -0.0614607 ,  0.65475965, -2.7329035 ,  5.578808  ,\n",
       "       -2.5066867 , -1.8912905 ,  0.3634988 ,  2.7395883 , -5.5817003 ,\n",
       "        0.6066571 , -2.2596807 , -2.6291995 ,  0.7854226 ,  1.9896873 ,\n",
       "        2.4007287 , -1.1938859 ,  2.7635882 ,  0.4408575 , -1.9049958 ,\n",
       "        0.526986  , -1.5615294 ,  1.6513894 ,  0.6793895 ,  0.5717171 ,\n",
       "       -2.8145156 ,  0.07670619,  1.4759918 , -0.63885576, -3.3751516 ,\n",
       "       -2.610316  , -0.7968178 ,  1.3870629 ,  0.16686264,  1.9244195 ,\n",
       "       -4.654755  , -1.3727199 ,  2.095118  , -2.8104064 ,  0.7448188 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"machine learn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqUSjLRy_isH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.24606967,  0.02924442,  2.606117  , -1.927406  , -9.501593  ,\n",
       "        6.6716948 ,  1.722619  , -2.0595136 , -0.7732086 ,  4.7558193 ,\n",
       "       -7.045576  , -1.5984142 ,  2.2007296 , -6.8144236 ,  9.329351  ,\n",
       "       -4.3544493 , -2.220007  , -1.5806001 ,  5.610407  , -8.2393265 ,\n",
       "        0.7217357 , -3.5028415 , -3.4166799 ,  1.1223906 ,  6.230218  ,\n",
       "        3.7619758 , -2.4158576 ,  4.420979  , -0.49613547, -3.1977272 ,\n",
       "        0.13617638, -4.364634  ,  3.0377398 ,  0.69782805, -0.01590317,\n",
       "       -2.9101572 ,  1.7207272 ,  1.0152985 , -2.8919737 , -3.701437  ,\n",
       "       -4.3352633 , -3.248755  ,  1.6562223 , -0.13792694,  2.2225308 ,\n",
       "       -9.367432  , -2.4254265 ,  4.229023  , -5.2904277 ,  1.785675  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.wv['machine']+model.wv['learn'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AxNRKUidrCk"
   },
   "outputs": [],
   "source": [
    "AI_categories = [\n",
    "              'Artificial Intelligence Applications - Expert Systems',\n",
    "              'Automatic Programming',\n",
    "              'Deduction - Theorem Proving',\n",
    "              'Knowledge Representation Formalisms - Knowledge Representation Methods',\n",
    "              'Programming Languages - Software',\n",
    "              'Learning',\n",
    "              'Natural Language Processing',\n",
    "              'Problem Solving - Control Methods - Search',\n",
    "              'Robotics',\n",
    "              'Vision - Scene Understanding',\n",
    "              'Distributed Artificial Intelligence',\n",
    "              'ARTIFICIAL INTELLIGENCE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QeWKP-k1qpy"
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "              'Natural language processing - Information extraction - Machine translation - Discourse, dialogue  pragmatics - Natural language generation - Speech recognition - Lexical semantics - Phonology / morphology',\n",
    "              'Knowledge representation reasoning - Description logics - Semantic networks Nonmonotonic default reasoning  belief revision - Probabilistic reasoning - Vagueness fuzzy logic - Causal reasoning  diagnostics - Temporal reasoning - Cognitive robotics - Ontology engineering - Logic programming answer set programming - Spatial  physical reasoning - Reasoning about belief  knowledge',\n",
    "              'Planning  scheduling - Planning for deterministic actions - Planning under uncertainty - Multi-agent planning - Planning  abstraction  generalization - Robotic planning - Evolutionary robotics',\n",
    "              'Search methodologies - Heuristic function construction - Discrete space search - Continuous space search - Randomized search - Game tree search - Abstraction  micro-operators - Search with partial observations - ',\n",
    "              'Control methods - Robotic planning - Evolutionary robotics - Computational control theory - Motion path planning',\n",
    "              'Philosophical theoretical foundations artificial intelligence - Cognitive science - Theory mind',\n",
    "              'Distributed artificial intelligence - Multi agent systems - Intelligent agents - Mobile agents - Cooperation  coordination',\n",
    "              'Computer vision - Biometrics - Scene understanding - Activity recognition  understanding - Video summarization - Visual content based indexing  retrieval - Visual inspection - Vision for robotics - Scene anomaly detection - Image  video acquisition - Camera calibration - Epipolar geometry - Computational photography - Hyperspectral imaging - Motion capture - 3D imaging - Active vision - Image representations - Shape representations - Appearance  texture - Hierarchical representations - Computer vision problems - Interest point  salient region detections - Image segmentation  - Video segmentation - Shape inference - Object detection - Object recognition - Object identification - Tracking - Reconstruction - Matching',\n",
    "              \n",
    "              'Learning paradigms - Supervised learning - Ranking - Learning to rank - Supervised learning  classification - Supervised learning  regression - Structured outputs - Cost sensitive learning - Unsupervised learning - Cluster analysis - Anomaly detection - Mixture modeling - Topic modeling - Source separation - Motif discovery - Dimensionality reduction  manifold learning - Reinforcement learning - Sequential decision making - Inverse reinforcement learning - Apprenticeship learning - Multi-agent reinforcement learning - Adversarial learning - Multi-task learning - Transfer learning - Lifelong machine learning - Learning under covariate shift',\n",
    "              'Learning settings - Batch learning - Online learning settings - Learning from demonstrations - Learning from critiques - Learning from implicit feedback - Active learning settings - Semi supervised learning settings',\n",
    "              'Machine learning approaches - Classification  regression trees - Kernel methods - Support vector machines - Gaussian processes - Neural networks - Logical  relational learning - Inductive logic learning - Statistical relational learning - Learning in probabilistic graphical models - Maximum likelihood modeling - Maximum entropy modeling - Maximum a posteriori modeling - Mixture models - Latent variable models - Bayesian network models - Learning linear models - Perceptron algorithm - Factorization methods - Non-negative matrix factorization - Factor analysis - Principal component analysis - Canonical correlation analysis - Latent Dirichlet allocation - Rule learning - Instance-based learning - Markov decision processes -  Markov decision processes - Stochastic games - Learning latent representations - Deep belief networks - Bio inspired approaches - Artificial life - Evolvable hardware - Genetic algorithms - Genetic programming - Evolutionary robotics - Generative  developmental approaches',\n",
    "              'Machine learning algorithms - Dynamic programming Markov decision processes - Value iteration - Q learning - Policy iteration - Temporal difference learning - Approximate dynamic programming methods - Ensemble methods - Boosting - Bagging - Spectral methods - Feature selection - Regularization',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-rtaQ7KbfQ_y",
    "outputId": "cd8e2034-6f91-44a3-f38d-1073e8cd6bda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.2585297, -1.09474, -0.51740396, -1.5583799, -1.277385, 1.2230147, 3.6439853, -1.6600533, 1.4912666, -2.3865879, 1.2189151, 0.5719612, 2.7518144, -2.781408, -2.061385, 2.1494553, 1.0412952, 2.237492, 0.14161092, -1.4961629, 1.8666816, -1.0945007, -0.40818986, -1.4722152, -0.20459145, 2.328488, -0.7185293, 0.63060343, -2.3967595, -1.0597452, 1.1229446, 1.805113, 1.015998, -2.1873384, -0.12749422, -0.016316757, 1.9769442, 0.9840427, -1.7754203, -3.5659814, 3.1010442, 2.0076227, 0.61076725, -0.32515174, -3.6688373, -1.054969, 2.3143127, 0.7147262, 1.1658139, 0.8725452], [-4.7960773, -1.7704331, -0.17159314, -1.5654887, -1.696463, 1.3633636, 2.3642745, -0.60040635, 1.4829278, -2.4751508, 1.0201765, 0.6441909, 2.688061, -2.4529297, 0.47901928, 2.3566878, 1.1981105, 0.46998572, 0.58817506, -0.64123666, 2.3364296, -2.3828585, 0.27646962, -0.96989816, 0.2530441, 1.0085167, -0.6223591, 0.35445678, -2.2382672, -0.57872456, 1.659824, 2.0099118, 2.595362, -0.9997726, -0.09018091, 0.8816102, 2.4655735, 0.8050124, -1.1530598, -3.0836341, 2.7684937, 1.0073061, 0.00575616, -0.57786924, -3.2156136, 0.95476097, 1.5965384, 0.76067203, 1.2837223, -0.3671839], [-4.783248, -2.4654036, 1.8282199, -3.2524014, -2.9422593, 0.47818545, 1.1319468, -0.48558038, 1.7362764, -1.7564304, 0.1713893, -1.0876645, 0.59644246, -0.96832526, 1.0853738, 3.143952, 2.3456964, -0.073322356, 0.8511666, -1.0623292, 2.6982129, -1.3787885, -1.641756, -2.0564864, -0.35710108, 1.4279834, -0.19134875, 1.7257166, -3.5816538, -0.40132627, 1.0557052, 2.7683246, 1.7407539, -1.9736162, 1.3690635, 0.73754, 2.0931156, 1.2272679, -0.3931911, -3.7137809, 4.2403607, 2.0456743, -1.8043844, -1.375812, -3.5201724, 0.74615204, 2.9523208, -0.55889595, -0.4305116, -0.6135682], [-2.6682758, -2.0906448, 0.3702082, -1.763951, -1.3056281, 1.2989495, 1.6341537, -0.018645708, 0.4660442, -1.3926327, 0.26077935, -0.09793859, 0.6407897, -1.0905774, -0.19085528, 3.055617, 1.3357424, 0.74421144, 0.957384, 0.028282428, 1.0109622, -0.707255, -0.27613002, -2.3247027, -0.9078487, 0.6687898, -0.690248, 1.9313891, -1.7434508, -1.0016263, 1.1569431, 1.4039564, 1.6583602, -1.4211533, 0.843102, 0.17694066, 1.8566834, -0.081796244, -0.5027641, -2.5389442, 2.543816, 1.2051241, -0.22449279, -0.8894108, -2.199338, -0.045534465, 0.24319553, -0.8911654, -0.7639756, -0.085744336], [-4.418727, -1.419803, 1.5708158, -2.6987824, -2.4854412, 0.5691688, 0.043044917, -0.27786833, 2.7932034, -1.7903156, 0.24949542, -0.038802195, 1.4238329, -1.541058, 0.14870362, 3.6138458, 2.4389935, 0.7642016, 1.1146837, -0.7245118, 2.6403756, -2.103103, -1.2469227, -2.0934734, -0.18935119, 1.6391281, -0.58698606, 1.9130386, -2.9331021, -0.7162676, 0.6673344, 3.0299964, 1.6199672, -2.2228365, 0.91334563, 0.24507749, 2.2792773, 0.3434165, -0.28254068, -3.0037558, 3.4233003, 2.5353255, -1.0407612, -0.71328354, -2.9894512, 0.39342391, 2.1154754, -0.6439582, -0.8723666, -0.69555795], [-3.6296988, -0.30504742, 0.021212062, -0.6736031, -1.7472433, 0.4192197, 1.2212005, -0.33318245, 2.3278158, -3.0614612, 1.4572011, 1.3329434, 3.8018093, -2.5337079, 0.4183, 3.3435352, 1.8631892, 1.0934873, 0.9327049, -0.9528741, 4.335353, -2.124141, -0.84434754, -1.9663016, 1.3545097, 2.332329, -0.03459015, 0.26926598, -1.432001, -0.26175267, -0.04326086, 2.207326, 3.1373577, -2.5924451, 0.79329664, 0.15286009, 3.5641758, 1.3748256, -1.4313527, -2.0387158, 0.45870805, 1.7892777, 0.7697367, -1.0888867, -2.8586924, 0.9864697, 1.1540154, -0.79008555, 3.1888273, -0.36340716], [-4.7498655, -2.0082538, 2.0650477, -2.6538336, -2.7813652, -0.2219172, 0.7528862, -0.7714873, 2.1804569, -1.7407357, 2.6121962, -0.9179781, 0.45030347, -1.7619938, 0.644618, 2.9984355, 1.8543806, 0.49087667, -1.310003, -1.2778642, 2.9742165, -0.60248816, -0.6721307, -1.7180697, 0.8103083, 3.1431892, -0.65900195, 1.890321, -3.1091056, -0.83834237, 0.22258794, 1.9165051, 1.5989912, -2.121817, 0.98958856, 0.33478117, 2.656167, 1.47242, 0.2738269, -3.0141346, 2.506883, 2.2542617, -1.8579614, -1.4157169, -2.2660065, 1.4739611, 1.986954, 0.2688377, -0.01116084, -0.7620956], [-3.8344402, -1.7627443, 0.013482263, -2.1556933, -1.7925524, 0.5110146, 2.7021735, -0.42457277, 1.7370346, -2.0547361, 0.58410996, -0.20980693, 2.604441, -1.3165913, -2.4578385, 3.5423813, 1.8524952, 1.6111225, 1.1050096, -1.8564557, 1.8394259, -1.8160945, -0.87464285, -1.9847978, -0.73219126, 2.048561, -2.068477, 2.7930079, -2.8351939, -0.62764347, 1.238038, 1.5283931, 0.47022444, -1.8407842, 0.7971539, 0.006729732, 2.448745, 0.88317794, -0.9530853, -3.3691823, 3.385877, 2.2737489, 1.5180569, 0.5125543, -2.8273292, -0.6604535, 3.147259, 1.0307336, -0.8378401, 0.48748377], [-4.803697, -1.6953143, 0.08243193, -2.7868576, -2.0559573, 2.293871, 2.5148377, -0.9782568, 1.3664638, -2.1174574, 1.8977991, -1.1527096, 1.0931118, -1.9012688, -0.6044156, 3.277232, 2.8219721, 0.6098037, -0.1970612, -1.9165957, 0.5713004, -1.1373634, -1.65581, -1.6858883, -1.1937876, 1.0006716, 0.09968073, 3.0323098, -3.7464862, 1.0631689, 0.57072383, 2.5665638, 0.49634123, -1.5698158, 0.793332, 0.3296176, 2.1543145, 0.988778, -0.8270112, -3.4312904, 2.691986, 2.053164, 1.0331227, -0.79652774, -3.6579661, 0.89351505, 1.0108926, 0.14591649, 0.24157651, -0.3091852], [-4.209945, -1.478514, -0.65360236, -1.3783714, -1.8534892, 3.2209125, 1.6276795, -0.23348632, 1.5915459, -1.4042844, 2.5756416, -0.7158973, 0.6250525, -1.7714843, -0.785086, 3.0324762, 3.3969445, 0.16155249, -0.36199412, -1.5491321, 0.7203293, -1.2083378, -0.15985551, -0.7954497, -1.4161118, 0.5783136, 0.24014375, 2.5570612, -2.4276257, 0.17151444, -0.32569277, 2.552733, 0.36257836, -1.5491463, 0.84296405, 0.37183225, 1.6477425, -0.04394825, -0.98846924, -2.1261923, 2.3017104, 1.5071672, 1.1247743, -2.111504, -3.1492555, 1.1366179, -0.5207402, -0.08834131, -0.002603922, 0.36255994], [-4.456132, -1.2375709, -0.060436487, -2.3262725, -1.5555788, 2.0290685, 2.1207979, -0.882367, 1.1406393, -2.1224058, 1.2132982, -0.7152811, 1.6820112, -2.1260521, -0.29163978, 3.8474853, 0.966945, 0.3466788, 0.27146608, -1.5148053, 0.41290393, -0.8747698, -1.4122522, -2.3614087, -1.1230488, 0.5673031, -0.25742036, 2.0600169, -2.3180704, 0.43655294, 0.39970943, 1.9141394, 1.0064878, -0.93134433, 0.5157056, -0.5070268, 2.3600667, 0.6129178, -0.55783105, -2.9124885, 2.026174, 1.5843923, 0.22606745, -0.513916, -3.4471755, 0.71103764, -0.028376233, 0.14374025, 0.2138857, -0.35969982], [-4.2178745, -1.4500127, 0.4737355, -3.1575625, -2.104847, 2.710899, 3.159836, -0.4343515, 0.928192, -2.8238966, 1.3814604, -1.0762248, 1.8243719, -2.1669593, -0.91299856, 4.3921742, 2.711184, 0.70554423, 0.39368823, -1.8234388, 0.099572524, -0.69179505, -0.965667, -3.43647, -1.9561361, 0.8922539, -0.62991774, 3.2562766, -3.4762852, 0.59666866, 0.14012648, 2.264789, 0.8790767, -1.3577005, 0.4756403, -0.35558546, 3.0121443, 0.12617694, -0.5292348, -3.7549527, 3.140975, 1.8866202, 0.7874215, -0.6871964, -4.3557415, 0.112307295, 0.04104868, -0.51128495, -0.5597852, -0.55689055]]\n"
     ]
    }
   ],
   "source": [
    "AI_vectors = []\n",
    "labels = []\n",
    "for item in categories:\n",
    "    vector_tmp = []\n",
    "    label = item.split('-')[0]\n",
    "    for phrase in item.split('-'):\n",
    "        phrase = phrase.lower().strip()\n",
    "        # print(phrase)\n",
    "        vector_tmp.append(model.wv[phrase])\n",
    "    # print('---')\n",
    "    AI_vectors.append(list(np.array(vector_tmp).mean(axis=0)))\n",
    "    labels.append(label)\n",
    "print(AI_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brCodssfgEgt"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(AI_vectors).to_csv('drive/My Drive/Data/FastText doc clusters - SIP/50D/classification/ACM_classifications_vectors')\n",
    "pd.DataFrame(labels,columns=['label']).to_csv('drive/My Drive/Data/FastText doc clusters - SIP/50D/classification/ACM_classifications_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMAHWCgX6kEz"
   },
   "source": [
    "### Get Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8LPLO5z4cER3"
   },
   "source": [
    "##### No n-gram handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lP8pYSjf6kiR",
    "outputId": "3293d0e4-ff19-437d-def6-b56259717fbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3184174/3184174 [27:52<00:00, 1903.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save in a dict\n",
    "comment_embedding = ''\n",
    "output_dict = {}\n",
    "for token in tqdm(corpus_tokens[:],total=len(corpus_tokens[:])):\n",
    "    output_dict[token] = str(model.wv[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AGLF7jepcI83"
   },
   "source": [
    "##### Manual n-gram handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w9cb-KpAcPWJ",
    "outputId": "4f2e771b-0fb9-487f-c7db-b11e3da36156"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:00<00:00, 10574.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save in a dict\n",
    "comment_embedding = 'average_manual '\n",
    "output_dict = {}\n",
    "for token in tqdm(corpus_tokens[:],total=len(corpus_tokens[:])):\n",
    "    token_split = token.split(' ')\n",
    "    if len(token_split) > 0:\n",
    "        tmp_vector_grams = []\n",
    "        for item in token_split:\n",
    "            tmp_vector_grams.append(model.wv[item])\n",
    "        output_dict[token] = str(list(np.array(tmp_vector_grams).mean(axis=0)))\n",
    "    else:\n",
    "        output_dict[token] = str(model.wv[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wk6CJa6pcQC-"
   },
   "source": [
    "##### Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4wRDXMX6tBH"
   },
   "outputs": [],
   "source": [
    "# Save embeddings to disk\n",
    "with open(directory+'/FastText vector with n-grams '+comment_embedding+period+'.json', 'w') as json_file:\n",
    "    json.dump(output_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ohPXzf8mKUxQ",
    "outputId": "4588f6a5-d865-48bb-fb40-d90033bc007a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive/My Drive/Data/corpus/improved_copyr_lemmatized_stopwords_removed_thesaurus_n-grams/\n"
     ]
    }
   ],
   "source": [
    "print(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yYjO-JQBLE3"
   },
   "source": [
    "### Get Doc Embeddings (SIF)\n",
    "\n",
    "It is not recommended to perform this on cloud, as it is not process intesive, yet takes too long depending on the doc-count. It might take over 30 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hp1fP9z4xUGX"
   },
   "source": [
    "Make a probability dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "buSIQtoWVnOz"
   },
   "outputs": [],
   "source": [
    "corpus_tokens_s = pd.Series(corpus_tokens)\n",
    "corpus_tokens_probabilities = (corpus_tokens_s.groupby(corpus_tokens_s).transform('count') / len(corpus_tokens_s)).values\n",
    "corpus_tokens_probabilities = pd.DataFrame(corpus_tokens_probabilities)\n",
    "corpus_tokens_probabilities['tokens'] = corpus_tokens_s\n",
    "corpus_tokens_probabilities.columns = ['probability','token']\n",
    "corpus_tokens_probabilities = corpus_tokens_probabilities.groupby('token').mean()\n",
    "corpus_tokens_probabilities = corpus_tokens_probabilities.reset_index()\n",
    "corpus_tokens_probabilities.columns = ['token','probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaa</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaai</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaai_conference</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaai_fall</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34364</th>\n",
       "      <td>zrm</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34365</th>\n",
       "      <td>zro</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34366</th>\n",
       "      <td>zsm</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34367</th>\n",
       "      <td>zurich</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34368</th>\n",
       "      <td>zynq</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34369 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 token  probability\n",
       "0                   aa     0.000039\n",
       "1                  aaa     0.000002\n",
       "2                 aaai     0.000010\n",
       "3      aaai_conference     0.000015\n",
       "4            aaai_fall     0.000003\n",
       "...                ...          ...\n",
       "34364              zrm     0.000005\n",
       "34365              zro     0.000003\n",
       "34366              zsm     0.000003\n",
       "34367           zurich     0.000002\n",
       "34368             zynq     0.000002\n",
       "\n",
       "[34369 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tokens_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qu51jQbo9QE6"
   },
   "source": [
    "Get vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "72BAU9Jm9PwE",
    "outputId": "1a4ef491-cceb-4fe7-9f10-18ffac71e652"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/34369 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 3613/34369 [00:00<00:00, 36128.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 7546/34369 [00:00<00:00, 37004.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 11958/34369 [00:00<00:00, 38884.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 16344/34369 [00:00<00:00, 40253.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 20647/34369 [00:00<00:00, 41047.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 24172/34369 [00:00<00:00, 38259.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 27630/34369 [00:00<00:00, 35683.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 34369/34369 [00:00<00:00, 38439.71it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34369"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = []\n",
    "for token in tqdm(corpus_tokens_probabilities['token'],total=corpus_tokens_probabilities.shape[0]):\n",
    "    phrase = token.replace(\"_\", \" \")\n",
    "    phrase = phrase.lower().strip()\n",
    "    phrase = phrase.split()\n",
    "    gram_vecs = []\n",
    "    for gram in phrase:\n",
    "        gram_vecs.append(model.wv[gram])\n",
    "    phrase_vec = np.array(gram_vecs).mean(axis=0)\n",
    "    vectors.append(phrase_vec)\n",
    "corpus_tokens_probabilities['vector'] = vectors\n",
    "len(corpus_tokens_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstracts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human machine interaction facial_expression_re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rule fuzzy_cognitive map natural_language_proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fog_computing architecture healthcare wireless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>argumentation knowledge_representation conflic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hydrothermal coordination power system scale i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>sequential fuzzy_clustering dynamic fuzzy neur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>daddy social_network_analysis car artificial_i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>unconventional cognitive enhancement option ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>technological_unemployment artificial_neural_n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>tital asynchronous multiplayer shooter procedu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6218 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              abstracts\n",
       "0     human machine interaction facial_expression_re...\n",
       "1     rule fuzzy_cognitive map natural_language_proc...\n",
       "2     fog_computing architecture healthcare wireless...\n",
       "3     argumentation knowledge_representation conflic...\n",
       "4     hydrothermal coordination power system scale i...\n",
       "...                                                 ...\n",
       "6213  sequential fuzzy_clustering dynamic fuzzy neur...\n",
       "6214  daddy social_network_analysis car artificial_i...\n",
       "6215  unconventional cognitive enhancement option ad...\n",
       "6216  technological_unemployment artificial_neural_n...\n",
       "6217  tital asynchronous multiplayer shooter procedu...\n",
       "\n",
       "[6218 rows x 1 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Y9rI72IxZal"
   },
   "source": [
    "Calculate weighted average vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4WwJtQqABN8w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/6218 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/6218 [00:01<1:50:41,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2/6218 [00:04<2:59:35,  1.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 3/6218 [00:06<3:06:03,  1.80s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 4/6218 [00:07<2:58:50,  1.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 5/6218 [00:09<3:02:30,  1.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 6/6218 [00:10<2:45:47,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 7/6218 [00:11<2:26:24,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 8/6218 [00:13<2:18:00,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 9/6218 [00:13<1:59:10,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 10/6218 [00:14<1:49:49,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 11/6218 [00:16<2:28:45,  1.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 12/6218 [00:19<3:04:24,  1.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 13/6218 [00:21<3:10:48,  1.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 14/6218 [00:22<2:56:09,  1.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 15/6218 [00:23<2:29:27,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 16/6218 [00:25<2:44:00,  1.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 17/6218 [00:27<3:04:21,  1.78s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 18/6218 [00:28<2:29:48,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 19/6218 [00:30<2:55:00,  1.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 20/6218 [00:32<2:40:17,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 21/6218 [00:34<2:55:34,  1.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 22/6218 [00:35<2:39:34,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 23/6218 [00:36<2:21:56,  1.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 24/6218 [00:37<2:20:07,  1.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 25/6218 [00:38<2:10:24,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 26/6218 [00:40<2:22:11,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 27/6218 [00:41<2:08:20,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 28/6218 [00:42<2:11:56,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 29/6218 [00:44<2:30:25,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 30/6218 [00:45<2:11:34,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 31/6218 [00:46<2:03:35,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 32/6218 [00:47<2:09:40,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 33/6218 [00:48<1:55:16,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 34/6218 [00:49<2:03:31,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 35/6218 [00:50<1:59:58,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 36/6218 [00:52<2:07:51,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 37/6218 [00:54<2:48:46,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 38/6218 [00:55<2:17:56,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 39/6218 [00:57<2:29:04,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 40/6218 [00:58<2:09:53,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 41/6218 [00:59<2:08:04,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 42/6218 [01:00<2:00:02,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 43/6218 [01:01<2:00:41,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 44/6218 [01:02<1:48:55,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 45/6218 [01:03<1:48:40,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 46/6218 [01:04<1:40:51,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 47/6218 [01:05<1:40:01,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 48/6218 [01:05<1:32:37,  1.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 49/6218 [01:06<1:31:55,  1.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 50/6218 [01:07<1:19:15,  1.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 51/6218 [01:08<1:28:27,  1.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 52/6218 [01:09<1:25:43,  1.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 53/6218 [01:11<2:01:15,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 54/6218 [01:12<1:57:57,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 55/6218 [01:13<1:56:54,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 56/6218 [01:14<2:05:12,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 57/6218 [01:16<2:34:24,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 58/6218 [01:18<2:29:40,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 59/6218 [01:19<2:24:34,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 60/6218 [01:20<2:20:18,  1.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 61/6218 [01:21<2:03:24,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 62/6218 [01:22<1:47:04,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 63/6218 [01:23<2:00:45,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 64/6218 [01:24<1:55:11,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 65/6218 [01:25<1:59:37,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 66/6218 [01:27<2:02:52,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 67/6218 [01:27<1:43:29,  1.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 68/6218 [01:29<2:00:52,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 69/6218 [01:30<2:02:23,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 70/6218 [01:33<2:41:36,  1.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 71/6218 [01:33<2:19:39,  1.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 72/6218 [01:34<2:02:36,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 73/6218 [01:35<1:58:16,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 74/6218 [01:36<1:54:58,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 75/6218 [01:37<1:37:50,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 76/6218 [01:38<1:35:25,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 77/6218 [01:39<1:30:19,  1.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 78/6218 [01:40<1:37:48,  1.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 79/6218 [01:41<1:35:18,  1.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 80/6218 [01:42<1:39:52,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 81/6218 [01:42<1:34:12,  1.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 82/6218 [01:44<2:09:06,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 83/6218 [01:47<2:38:52,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 84/6218 [01:48<2:32:23,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 85/6218 [01:49<2:04:54,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 86/6218 [01:50<2:11:23,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 87/6218 [01:51<2:06:16,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 88/6218 [01:52<2:00:37,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 89/6218 [01:53<1:55:40,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 90/6218 [01:55<2:08:09,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 91/6218 [01:56<2:12:16,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 92/6218 [01:58<2:16:36,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 93/6218 [01:59<2:04:00,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 94/6218 [02:00<2:24:17,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 95/6218 [02:02<2:16:22,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 96/6218 [02:02<2:02:25,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 97/6218 [02:04<2:09:46,  1.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 98/6218 [02:05<1:53:47,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 99/6218 [02:06<1:58:28,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 100/6218 [02:07<1:44:16,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 101/6218 [02:08<1:44:08,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 102/6218 [02:09<1:39:45,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 103/6218 [02:10<1:40:12,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 104/6218 [02:11<1:57:28,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 105/6218 [02:13<2:08:58,  1.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 106/6218 [02:14<2:01:18,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 107/6218 [02:15<1:57:55,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 108/6218 [02:16<1:49:04,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 109/6218 [02:17<1:47:08,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 110/6218 [02:18<2:03:36,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 111/6218 [02:20<2:08:13,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 112/6218 [02:21<2:11:17,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 113/6218 [02:22<2:16:06,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 114/6218 [02:23<2:04:14,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 115/6218 [02:26<2:57:33,  1.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 116/6218 [02:29<3:27:09,  2.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 117/6218 [02:31<3:15:20,  1.92s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 118/6218 [02:32<2:49:14,  1.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 119/6218 [02:33<2:24:42,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 120/6218 [02:35<2:53:36,  1.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 121/6218 [02:36<2:21:46,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 122/6218 [02:37<2:23:37,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 123/6218 [02:38<2:20:30,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 124/6218 [02:39<2:01:17,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 125/6218 [02:41<2:10:19,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 126/6218 [02:43<2:43:05,  1.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 127/6218 [02:45<2:50:26,  1.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 128/6218 [02:46<2:42:11,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 129/6218 [02:48<2:36:29,  1.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 130/6218 [02:49<2:23:54,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 131/6218 [02:52<3:32:37,  2.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 132/6218 [02:54<3:10:05,  1.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 133/6218 [02:55<2:52:59,  1.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 134/6218 [02:56<2:32:06,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 135/6218 [02:58<2:44:54,  1.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 136/6218 [02:59<2:22:15,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 137/6218 [03:00<2:08:44,  1.27s/it]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 138/6218 [03:01<2:11:20,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 139/6218 [03:02<2:00:08,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 140/6218 [03:03<1:47:38,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 141/6218 [03:04<1:44:55,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 142/6218 [03:05<1:52:55,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 143/6218 [03:07<2:03:15,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 144/6218 [03:09<2:25:24,  1.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 145/6218 [03:10<2:23:07,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 146/6218 [03:11<2:08:03,  1.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 147/6218 [03:13<2:23:53,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 148/6218 [03:14<2:12:30,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 149/6218 [03:15<2:22:53,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 150/6218 [03:17<2:34:48,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 151/6218 [03:19<2:37:53,  1.56s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 152/6218 [03:21<2:59:24,  1.77s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 153/6218 [03:23<3:00:45,  1.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 154/6218 [03:24<2:42:58,  1.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 155/6218 [03:27<3:34:52,  2.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 156/6218 [03:30<3:43:37,  2.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 157/6218 [03:31<3:21:29,  1.99s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 158/6218 [03:34<3:25:29,  2.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 159/6218 [03:35<3:15:33,  1.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 160/6218 [03:36<2:51:14,  1.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 161/6218 [03:38<2:56:22,  1.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 162/6218 [03:39<2:41:19,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 163/6218 [03:41<2:38:53,  1.57s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 164/6218 [03:42<2:33:29,  1.52s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 165/6218 [03:44<2:39:37,  1.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 166/6218 [03:45<2:27:00,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 167/6218 [03:47<2:23:55,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 168/6218 [03:48<2:09:37,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 169/6218 [03:50<2:31:59,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 170/6218 [03:54<3:51:02,  2.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 171/6218 [03:57<4:10:45,  2.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 172/6218 [03:58<3:39:48,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 173/6218 [04:00<3:39:28,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 174/6218 [04:02<3:32:05,  2.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 175/6218 [04:04<3:23:15,  2.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 176/6218 [04:05<2:47:33,  1.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 177/6218 [04:06<2:19:20,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 178/6218 [04:07<2:23:04,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 179/6218 [04:08<2:16:06,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 180/6218 [04:10<2:24:09,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 181/6218 [04:11<2:26:01,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 182/6218 [04:12<2:11:47,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 183/6218 [04:13<1:49:48,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 184/6218 [04:14<1:47:58,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 185/6218 [04:16<2:05:26,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 186/6218 [04:17<2:08:49,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 187/6218 [04:18<2:03:21,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 188/6218 [04:21<2:44:42,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 189/6218 [04:22<2:34:25,  1.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 190/6218 [04:24<2:33:37,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 191/6218 [04:25<2:18:51,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 192/6218 [04:26<2:23:47,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 193/6218 [04:27<2:14:29,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 194/6218 [04:28<2:05:41,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 195/6218 [04:30<2:24:50,  1.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 196/6218 [04:33<2:52:52,  1.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 197/6218 [04:34<2:31:17,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 198/6218 [04:35<2:26:31,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 199/6218 [04:36<2:06:18,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 200/6218 [04:37<2:11:28,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 201/6218 [04:39<2:22:54,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 202/6218 [04:40<2:13:26,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 203/6218 [04:41<2:13:56,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 204/6218 [04:42<1:48:49,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 205/6218 [04:43<1:38:48,  1.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 206/6218 [04:43<1:34:43,  1.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 207/6218 [04:45<1:45:56,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 208/6218 [04:46<1:43:52,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 209/6218 [04:47<1:50:49,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 210/6218 [04:47<1:27:59,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 211/6218 [04:49<1:46:39,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 212/6218 [04:50<2:00:24,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 213/6218 [04:51<1:49:48,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 214/6218 [04:52<1:37:21,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 215/6218 [04:53<1:49:05,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 216/6218 [04:54<1:46:10,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 217/6218 [04:56<1:55:16,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 218/6218 [04:57<1:56:59,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 219/6218 [04:58<2:09:35,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 220/6218 [05:00<2:14:28,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 221/6218 [05:01<2:11:58,  1.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 222/6218 [05:02<2:05:37,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 223/6218 [05:05<2:40:51,  1.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 224/6218 [05:07<2:55:29,  1.76s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 225/6218 [05:10<3:31:39,  2.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 226/6218 [05:12<3:31:57,  2.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 227/6218 [05:13<3:04:39,  1.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 228/6218 [05:14<2:50:24,  1.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 229/6218 [05:16<2:39:47,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 230/6218 [05:17<2:37:12,  1.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 231/6218 [05:19<2:27:26,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 232/6218 [05:22<3:38:51,  2.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 233/6218 [05:25<3:41:17,  2.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 234/6218 [05:27<3:43:56,  2.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 235/6218 [05:28<3:01:19,  1.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 236/6218 [05:29<2:29:55,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 237/6218 [05:29<2:07:21,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 238/6218 [05:32<2:32:48,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 239/6218 [05:33<2:22:49,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 240/6218 [05:34<2:24:13,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 241/6218 [05:36<2:20:49,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 242/6218 [05:37<2:33:13,  1.54s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 243/6218 [05:38<2:08:40,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 244/6218 [05:39<1:54:32,  1.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 245/6218 [05:41<2:22:16,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 246/6218 [05:42<2:16:14,  1.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 247/6218 [05:43<2:10:42,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 248/6218 [05:45<2:29:30,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 249/6218 [05:47<2:20:33,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 250/6218 [05:48<2:18:27,  1.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 251/6218 [05:49<2:18:57,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 252/6218 [05:51<2:31:46,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 253/6218 [05:52<2:22:02,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 254/6218 [05:54<2:41:21,  1.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 255/6218 [05:56<2:26:33,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 256/6218 [05:56<2:09:47,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 257/6218 [05:57<1:52:07,  1.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 258/6218 [05:59<2:18:06,  1.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 259/6218 [06:00<1:54:54,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 260/6218 [06:01<2:01:34,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 261/6218 [06:02<1:46:18,  1.07s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 262/6218 [06:03<1:51:26,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 263/6218 [06:05<2:00:17,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 264/6218 [06:06<1:59:27,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 265/6218 [06:07<1:50:37,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 266/6218 [06:08<1:59:12,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 267/6218 [06:10<2:08:34,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 268/6218 [06:11<2:05:39,  1.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 269/6218 [06:12<2:08:18,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 270/6218 [06:13<2:02:02,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 271/6218 [06:14<1:49:39,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 272/6218 [06:15<1:56:37,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 273/6218 [06:18<2:27:18,  1.49s/it]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 274/6218 [06:18<2:06:03,  1.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 275/6218 [06:20<2:03:38,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 276/6218 [06:20<1:55:51,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 277/6218 [06:21<1:44:04,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 278/6218 [06:23<1:56:47,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 279/6218 [06:24<1:49:26,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 280/6218 [06:25<1:52:22,  1.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 281/6218 [06:28<2:40:59,  1.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 282/6218 [06:29<2:31:45,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 283/6218 [06:30<2:26:45,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 284/6218 [06:32<2:38:49,  1.61s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 285/6218 [06:33<2:27:07,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 286/6218 [06:35<2:23:18,  1.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 287/6218 [06:36<2:16:15,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 288/6218 [06:38<2:27:19,  1.49s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 289/6218 [06:38<2:04:29,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 290/6218 [06:40<2:02:33,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 291/6218 [06:41<2:08:23,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 292/6218 [06:42<1:58:41,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 293/6218 [06:44<2:04:50,  1.26s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 294/6218 [06:44<1:48:58,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 295/6218 [06:46<1:54:47,  1.16s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 296/6218 [06:46<1:37:11,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 297/6218 [06:47<1:37:10,  1.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 298/6218 [06:48<1:35:30,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 299/6218 [06:51<2:20:21,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 300/6218 [06:52<2:11:24,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 301/6218 [06:52<1:49:19,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 302/6218 [06:54<1:55:48,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 303/6218 [06:55<1:59:32,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 304/6218 [06:56<2:01:55,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 305/6218 [06:58<2:25:38,  1.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 306/6218 [07:01<2:58:55,  1.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 307/6218 [07:03<3:02:15,  1.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 308/6218 [07:04<2:45:06,  1.68s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 309/6218 [07:05<2:20:14,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 310/6218 [07:06<2:13:40,  1.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 311/6218 [07:07<2:01:49,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 312/6218 [07:09<2:20:25,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 313/6218 [07:11<2:30:06,  1.53s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 314/6218 [07:13<2:42:13,  1.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 315/6218 [07:14<2:43:31,  1.66s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 316/6218 [07:15<2:27:56,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 317/6218 [07:17<2:37:20,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 318/6218 [07:18<2:10:56,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 319/6218 [07:19<2:18:44,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 320/6218 [07:20<2:04:52,  1.27s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 321/6218 [07:21<1:41:14,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 322/6218 [07:25<3:07:39,  1.91s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 323/6218 [07:26<2:48:14,  1.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 324/6218 [07:28<2:45:36,  1.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 325/6218 [07:30<2:59:36,  1.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 326/6218 [07:31<2:40:51,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 327/6218 [07:33<2:55:25,  1.79s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 328/6218 [07:34<2:39:47,  1.63s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 329/6218 [07:36<2:36:52,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 330/6218 [07:38<2:38:56,  1.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 331/6218 [07:39<2:20:16,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 332/6218 [07:40<2:27:16,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 333/6218 [07:41<2:16:27,  1.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 334/6218 [07:42<2:02:31,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 335/6218 [07:43<1:55:45,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 336/6218 [07:45<2:01:09,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 337/6218 [07:46<1:58:14,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 338/6218 [07:48<2:27:45,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 339/6218 [07:51<3:06:31,  1.90s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 340/6218 [07:52<2:36:24,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 341/6218 [07:53<2:18:42,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 342/6218 [07:54<2:16:01,  1.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 343/6218 [07:57<2:48:23,  1.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 344/6218 [07:58<2:46:47,  1.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 345/6218 [08:00<2:40:42,  1.64s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 346/6218 [08:02<2:56:55,  1.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 347/6218 [08:05<3:38:32,  2.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 348/6218 [08:07<3:11:32,  1.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 349/6218 [08:08<3:01:01,  1.85s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 350/6218 [08:09<2:23:02,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 351/6218 [08:11<2:36:46,  1.60s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 352/6218 [08:12<2:28:04,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 353/6218 [08:13<2:26:50,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 354/6218 [08:14<2:08:55,  1.32s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 355/6218 [08:17<2:46:10,  1.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 356/6218 [08:18<2:41:06,  1.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 357/6218 [08:19<2:17:28,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 358/6218 [08:20<1:57:56,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 359/6218 [08:22<2:12:30,  1.36s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 360/6218 [08:23<2:20:04,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 361/6218 [08:24<1:59:46,  1.23s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 362/6218 [08:25<1:46:41,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 363/6218 [08:26<1:41:13,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 364/6218 [08:27<1:41:24,  1.04s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 365/6218 [08:28<1:34:55,  1.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 366/6218 [08:29<1:58:04,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 367/6218 [08:31<2:22:46,  1.46s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 368/6218 [08:32<2:09:37,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 369/6218 [08:34<2:05:16,  1.29s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 370/6218 [08:36<2:23:15,  1.47s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 371/6218 [08:37<2:18:35,  1.42s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 372/6218 [08:38<1:58:54,  1.22s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 373/6218 [08:39<1:53:53,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 374/6218 [08:40<2:09:42,  1.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 375/6218 [08:42<2:05:03,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 376/6218 [08:42<1:54:18,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 377/6218 [08:44<1:54:07,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 378/6218 [08:45<1:49:02,  1.12s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 379/6218 [08:46<1:47:21,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 380/6218 [08:48<2:14:41,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 381/6218 [08:49<2:00:24,  1.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 382/6218 [08:49<1:46:18,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 383/6218 [08:51<1:48:11,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 384/6218 [08:53<2:13:30,  1.37s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 385/6218 [08:54<2:10:43,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 386/6218 [08:55<2:05:54,  1.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 387/6218 [08:57<2:15:24,  1.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 388/6218 [08:59<2:36:59,  1.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 389/6218 [09:00<2:25:53,  1.50s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 390/6218 [09:01<2:14:23,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 391/6218 [09:02<2:11:26,  1.35s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 392/6218 [09:04<2:14:59,  1.39s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 393/6218 [09:06<2:37:40,  1.62s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 394/6218 [09:08<2:55:44,  1.81s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 395/6218 [09:09<2:20:01,  1.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 396/6218 [09:10<2:14:13,  1.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 397/6218 [09:12<2:30:23,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 398/6218 [09:14<2:40:03,  1.65s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 399/6218 [09:15<2:33:13,  1.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 400/6218 [09:17<2:30:30,  1.55s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 401/6218 [09:19<2:44:22,  1.70s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 402/6218 [09:21<2:43:42,  1.69s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 403/6218 [09:21<2:10:04,  1.34s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 404/6218 [09:23<2:18:15,  1.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 405/6218 [09:24<2:03:53,  1.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 406/6218 [09:25<1:53:38,  1.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 407/6218 [09:25<1:46:03,  1.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 408/6218 [09:27<1:54:42,  1.18s/it]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 409/6218 [09:28<2:03:10,  1.27s/it]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 410/6218 [09:31<2:32:22,  1.57s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "a = 1e-3\n",
    "embedding_size = 50\n",
    "\n",
    "doc_set = []\n",
    "for doc in tqdm(corpus['abstracts'].values.tolist(),total=len(corpus['abstracts'].values.tolist())):\n",
    "    vs = np.zeros(embedding_size)  # add all word2vec values into one vector for the sentence\n",
    "    doc_length = len(doc.split())\n",
    "#     print(doc.split())\n",
    "    for word in doc.split():\n",
    "        a_value = a / (a + corpus_tokens_probabilities[corpus_tokens_probabilities['token']==word]['probability'].values.tolist()[0])  # smooth inverse frequency, SIF\n",
    "        vs = np.add(vs, np.multiply(a_value, corpus_tokens_probabilities[corpus_tokens_probabilities['token']==word]['vector'].values.tolist()[0]))  # vs += sif * word_vector\n",
    "\n",
    "    vs = np.divide(vs, doc_length)  # weighted average\n",
    "    doc_set.append(vs)  # add to our existing re-calculated set of sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(doc_set).to_csv('/home/sahand/Data/corpus/improved_copyr_thesaurus/n-grams/vectors/'+period+' vectors SIF',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6L6EqReXxgPX"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_m00tKKkKNG"
   },
   "source": [
    "# Train on a large Scopus corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nz7pfl9d6R9o"
   },
   "source": [
    "#### Load Corpus Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VuO0J8oxkKWz"
   },
   "outputs": [],
   "source": [
    "sentence_corpus = pd.read_csv('/home/sahand/Data/1900-2019 corpus sentences abstract-title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYHEYxwpEgCi"
   },
   "source": [
    "#### Preprocess and prepare corpus for FastText training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tkqrGJ3cEgnX",
    "outputId": "0b5441c0-1785-4a1e-83e7-6b6c995d31b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13307816/13307816 [1:20:43<00:00, 2747.84it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "with open('/home/sahand/Data/1900-2019 corpus sentences abstract-title further processed - no lem - w1.csv', 'w') as f:\n",
    "    for index,row in tqdm(sentence_corpus.iterrows(),total=sentence_corpus.shape[0]):\n",
    "        sentence = row['sentence']\n",
    "        sentence = re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",sentence)\n",
    "        sentence = word_tokenize(sentence)\n",
    "        sentence = [word for word in sentence if (not word in punkts) and len(word)>1] \n",
    "#         sentence = [lemmatizer.lemmatize(word) for word in sentence]\n",
    "        # sentences.append(sentence)\n",
    "        f.write(\"%s\\n\" % ' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qQHwYepMdKFc"
   },
   "source": [
    "#### Save sentences to disk for future use -- Not needed anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJZ0UwdhdOlp"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([' '.join(words) for words in sentences],columns=['sentences']).to_csv(\n",
    "    'drive/My Drive/Data/corpus/AI ALL/1900-2019 corpus sentences abstract-title further processed.csv',\n",
    "    header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-j6H5hsfu8p0"
   },
   "source": [
    "#### Load pre-processed sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yLHxqzOPvCdV",
    "outputId": "9171ddac-0f5d-4dfe-8bc9-99e563071495"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13145868/13145868 [22:04<00:00, 9924.10it/s] \n"
     ]
    }
   ],
   "source": [
    "sentence_corpus = pd.read_csv('/home/sahand/Data/1900-2019 corpus sentences abstract-title further processed - no lem - w2.csv',delimiter=\";;;\")\n",
    "sentence_corpus.columns = [\"sentences\"]\n",
    "sentences = []\n",
    "sentence_corpus = sentence_corpus.fillna('')\n",
    "for index,row in tqdm(sentence_corpus.iterrows(),total=sentence_corpus.shape[0]):\n",
    "    sentences.append(row['sentences'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "UA83SDYjwfrO",
    "outputId": "62a9447a-3b75-40ef-bd4a-2910968b284f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the hardware of computers, e.g.</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>circuits, sequential circuits or vlsi chips, r...</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>the design of efficient hardware is a fundamen...</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>because of the large cost for the physical con...</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>for these purposes data structures for boolean...</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>the corresponding state of the art data struct...</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>efficient algorithms for the operations on obd...</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>a generalized data structure called graph-driv...</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>the new data structure allows for many importa...</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>efficient algorithms for the operations on gra...</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_index                                           sentence    year\n",
       "0              0                   the hardware of computers, e.g.   1994.0\n",
       "1              0  circuits, sequential circuits or vlsi chips, r...  1994.0\n",
       "2              0  the design of efficient hardware is a fundamen...  1994.0\n",
       "3              0  because of the large cost for the physical con...  1994.0\n",
       "4              0  for these purposes data structures for boolean...  1994.0\n",
       "5              0  the corresponding state of the art data struct...  1994.0\n",
       "6              0  efficient algorithms for the operations on obd...  1994.0\n",
       "7              0  a generalized data structure called graph-driv...  1994.0\n",
       "8              0  the new data structure allows for many importa...  1994.0\n",
       "9              0  efficient algorithms for the operations on gra...  1994.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_corpus.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-9A4hbD7xwV"
   },
   "source": [
    "### Train Fasttext - Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MYfn-ZQfhed1"
   },
   "source": [
    "#### Load a model to continue training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Bnu7_aMhu-A"
   },
   "source": [
    "* If want to continue training, run this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7eHrQg_g2ej"
   },
   "outputs": [],
   "source": [
    "model = load(gensim_model_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s07ymd4xhtWh"
   },
   "outputs": [],
   "source": [
    "model.build_vocab(sentences, update=True)\n",
    "model.train(sentences, total_examples=len(sentences), epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9LWfxerh2DI"
   },
   "source": [
    "* Otherwise run this section\n",
    "\n",
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsDmFFxp7yJa"
   },
   "outputs": [],
   "source": [
    "model = fasttext_gensim(min_n=3, max_n=6, size=15, window=5, min_count=1, seed = 50)\n",
    "model.build_vocab(sentences=sentences)\n",
    "model.train(sentences=sentences, total_examples=len(sentences), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqV_noKRcD4b"
   },
   "outputs": [],
   "source": [
    "fname = \"drive/My Drive/Data/Models/fasttext-scopus-2.2-million_docs-gensim 15D.model\"\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3vrtHdqHy-K"
   },
   "outputs": [],
   "source": [
    "model = fasttext_gensim(min_n=3, max_n=6, size=50, window=5, min_count=1, seed = 50)\n",
    "model.build_vocab(sentences=sentences)\n",
    "model.train(sentences=sentences, total_examples=len(sentences), epochs=10)\n",
    "fname = \"/home/sahand/Data/models/fasttext-scopus-2.2-million_docs-gensim 50D-w1.model\"\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g75Pt__ZH4RZ"
   },
   "outputs": [],
   "source": [
    "model = fasttext_gensim(min_n=3, max_n=6, size=100, window=5, min_count=1, seed = 50)\n",
    "model.build_vocab(sentences=sentences)\n",
    "model.train(sentences=sentences, total_examples=len(sentences), epochs=10)\n",
    "fname = \"/home/sahand/Data/models/fasttext-scopus-2.2-million_docs-gensim 100D-w1.model\"\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mnTG0yUGiqxw"
   },
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVJoU_sLiw2E"
   },
   "outputs": [],
   "source": [
    "similarities = model.wv.most_similar(positive=['logic','fuzzy','expert'],negative=['deep','neural','network','cnn','ann'])\n",
    "most_similar = similarities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JaKS52YSDcup",
    "outputId": "c4257bf2-6134-4a85-df40-d7696a731c57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mam-rnn', 0.9763791561126709)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkokDJdHjEFz"
   },
   "outputs": [],
   "source": [
    "not_matching = model.wv.doesnt_match(\"human computer interface tree\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7fOp26djDYk7",
    "outputId": "3fca5ff0-ac5a-464e-ddf8-4662385b6c82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tree'"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x7RJl89QjMhl"
   },
   "outputs": [],
   "source": [
    "sim_score = model.wv.similarity('computer', 'human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DtlAXvqWDWo4",
    "outputId": "639a0234-75f9-4fec-c4ee-09d607516050"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7571839"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "xWLLBs8UBRwy",
    "outputId": "836cc23e-4ba9-4dfd-dfaa-21f5dd09f25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2783480e+00 -4.2018552e+00  7.1276689e-01  4.2023015e+00\n",
      " -5.0359420e-03  4.4385982e+00  6.2421050e+00 -8.9032326e+00\n",
      "  1.7556003e+00  1.3425230e+00  9.4295764e-01 -4.4485557e-01\n",
      " -5.8648558e+00  2.6428668e+00 -1.2076639e+00]\n",
      "[  3.7072854   -3.616749     1.3040072    0.234361    -2.753659\n",
      "   7.528801    14.293305   -14.688236     5.3885765    6.496681\n",
      "   1.9917868    2.855616    -0.05153261   7.8660994   -2.22459   ]\n",
      "[  0.28606984  -6.971052    -0.9232919   11.48035      0.2561571\n",
      "   4.084776     2.4220266   -8.616226     0.94255084  -2.2498865\n",
      "   1.7112938   -3.370861   -12.577294    -1.1608386   -0.04991044]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['artificial intelligence'])\n",
    "print(model.wv['artificial'])\n",
    "print(model.wv['intelligence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sSZfjEMUyMc"
   },
   "source": [
    "### Train Fasttext - Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oK4N7jUqU1CJ"
   },
   "outputs": [],
   "source": [
    "sentences_joined = ' '.join(sentences)\n",
    "model = fasttext.train_unsupervised(sentences_joined, \"cbow\", minn=2, maxn=5, dim=50, epoch=10,lr=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLNquk0BaywP"
   },
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9i6detxZVMUQ"
   },
   "outputs": [],
   "source": [
    "model.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o13SRSefVFDD"
   },
   "outputs": [],
   "source": [
    "model.get_word_vector(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FvMFASYVNzs"
   },
   "outputs": [],
   "source": [
    "model.get_nearest_neighbors('asparagus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TH9Wdf5WV5F8"
   },
   "outputs": [],
   "source": [
    "model.get_analogies(\"intelligence\", \"math\", \"fuzzy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaDnem0pWcNw"
   },
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8wjWeyw-Wbpi"
   },
   "outputs": [],
   "source": [
    "model.save_model(\"drive/My Drive/Data/fasttext-scopus_wos-merged-310k_docs-facebook.ftz\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "r_m00tKKkKNG"
   ],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "fasttext_embedding.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
