{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sahand/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sahand/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sahand/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import gc\n",
    "import collections\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pprint\n",
    "from random import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, SpectralClustering, AffinityPropagation\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy import spatial,sparse,sign\n",
    "\n",
    "from bokeh.io import push_notebook, show, output_notebook, output_file\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import fasttext\n",
    "from gensim.models import FastText as fasttext_gensim\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "from sciosci.assets import keyword_assets as kw\n",
    "from sciosci.assets import generic_assets as sci\n",
    "from sciosci.assets import advanced_assets as aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cluster centers\n",
    "cluster_centers = pd.read_csv('/home/sahand/GoogleDrive/Data/FastText doc clusters - SIP/50D/cluster_centers/agglomerative ward 1990-2004 7',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ACM classifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and make keyword list\n",
    "keywords = pd.read_csv('/home/sahand/GoogleDrive/Data/Author keywords - 02 Nov 2019/2017-2018 keyword frequency',names=['keyword','frequency'])\n",
    "keywords = keywords[keywords['frequency']>20]\n",
    "keywords_list = keywords['keyword'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "gensim_model_address = '/home/sahand/GoogleDrive/Data/FastText Models/50D/fasttext-scopus_wos-merged-310k_docs-gensim 50D.model'\n",
    "model = fasttext_gensim.load(gensim_model_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in a list\n",
    "keyword_vectors = []\n",
    "for token in tqdm(keywords_list[:],total=len(keywords_list[:])):\n",
    "    keyword_vectors.append(model.wv[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing vector of cluster with vectors of the n-grams from ACM/CORE classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing vector of cluster with vectors of the n-grams from AuKeyWord / KeywordPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine distance of the cluster centers and keywords to find the closest keywords to clusters\n",
    "names = []\n",
    "names.append('cluster_1')\n",
    "sim_A_to_B = []\n",
    "for idx_A,vector_A in cluster_centers.iterrows():\n",
    "    inner_similarity_scores = []\n",
    "    inner_similarity_scores.append(idx_A)\n",
    "    for idx_B,vector_B in enumerate(keyword_vectors):\n",
    "        distance_tmp = spatial.distance.cosine(vector_A.values, vector_B)\n",
    "        similarity_tmp = 1 - distance_tmp\n",
    "\n",
    "        inner_similarity_scores.append(idx_B)\n",
    "        inner_similarity_scores.append(similarity_tmp)\n",
    "\n",
    "        if idx_A == 0:\n",
    "            names.append('cluster_2_'+str(idx_B))\n",
    "            names.append('similarity_'+str(idx_B))\n",
    "\n",
    "    sim_A_to_B.append(inner_similarity_scores)\n",
    "        # print('cluster of A:',idx_A,'to cluster of B:',idx_B,'similarity',similarity_tmp)\n",
    "\n",
    "sim_A_to_B = pd.DataFrame(sim_A_to_B,columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
